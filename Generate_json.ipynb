{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNaEHUQuE3roh7v5z1ZcCmH",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/JorgeAnsotegui/TFM/blob/main/Generate_json.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fJLYj_ZSmtNt",
        "outputId": "be40b68a-a856-4cea-ff9a-c2e09c1278f0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n",
            "Archivo copiado a: /content/Dataset/Polipos/Polipos Segmentados.zip\n",
            "Archivo descomprimido en: /content/Dataset/Polipos\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "import shutil\n",
        "import zipfile\n",
        "import os\n",
        "\n",
        "# Montar Google Drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "\n",
        "\n",
        "# Definir las rutas de los archivos y directorios\n",
        "source_file = '/content/drive/MyDrive/TFM/Polipos Segmentados.zip'\n",
        "destination_dir = '/content/Dataset/Polipos'\n",
        "\n",
        "# Crear el directorio si no existe\n",
        "if not os.path.exists(destination_dir):\n",
        "    os.makedirs(destination_dir)\n",
        "\n",
        "# Copiar el archivo\n",
        "shutil.copy(source_file, destination_dir)\n",
        "print(f'Archivo copiado a: {os.path.join(destination_dir, os.path.basename(source_file))}')\n",
        "\n",
        "# Descomprimir el archivo ZIP\n",
        "zip_path = os.path.join(destination_dir, os.path.basename(source_file))\n",
        "with zipfile.ZipFile(zip_path, 'r') as zip_ref:\n",
        "    zip_ref.extractall(destination_dir)\n",
        "    print(f'Archivo descomprimido en: {destination_dir}')\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import shutil\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Definir las rutas de los archivos y directorios\n",
        "source_dir = '/content/Dataset/Polipos/segmentación polipos 265'\n",
        "destination_base_dir = '/content/Dataset/Polipos/TrainValTest'\n",
        "\n",
        "# Crear directorios de destino si no existen\n",
        "train_dir = os.path.join(destination_base_dir, 'train')\n",
        "val_dir = os.path.join(destination_base_dir, 'val')\n",
        "test_dir = os.path.join(destination_base_dir, 'test')\n",
        "\n",
        "os.makedirs(train_dir, exist_ok=True)\n",
        "os.makedirs(val_dir, exist_ok=True)\n",
        "os.makedirs(test_dir, exist_ok=True)\n",
        "\n",
        "# Listar todas las imágenes en el directorio fuente, excluyendo las que terminan en (1).jpg\n",
        "all_images = [f for f in os.listdir(source_dir) if f.endswith('.jpg') and not f.endswith('(1).jpg')]\n",
        "\n",
        "# Dividir las imágenes en train (60%), val (20%), y test (20%)\n",
        "train_images, test_images = train_test_split(all_images, test_size=0.4, random_state=42)\n",
        "val_images, test_images = train_test_split(test_images, test_size=0.5, random_state=42)\n",
        "\n",
        "# Función para copiar imágenes a los directorios correspondientes\n",
        "def copy_images(image_list, destination_dir):\n",
        "    for image in image_list:\n",
        "        source_file = os.path.join(source_dir, image)\n",
        "        destination_file = os.path.join(destination_dir, image)\n",
        "        shutil.copyfile(source_file, destination_file)\n",
        "\n",
        "copy_images(train_images, train_dir)\n",
        "copy_images(val_images, val_dir)\n",
        "copy_images(test_images, test_dir)\n",
        "\n",
        "print(\"División de imágenes completada.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B__RUYfHvyyr",
        "outputId": "0a66026a-4054-4c43-f1d2-5a9b42fb2443"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "División de imágenes completada.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import cv2\n",
        "import numpy as np\n",
        "import json\n",
        "\n",
        "def find_contours(image_path):\n",
        "    # Cargar la imagen\n",
        "    image = cv2.imread(image_path)\n",
        "    # Convertir a espacio de color HSV\n",
        "    hsv = cv2.cvtColor(image, cv2.COLOR_BGR2HSV)\n",
        "    # Definir el rango de color amarillo en HSV\n",
        "    lower_yellow = np.array([20, 100, 100])\n",
        "    upper_yellow = np.array([30, 255, 255])\n",
        "    # Crear una máscara para detectar el color amarillo\n",
        "    mask = cv2.inRange(hsv, lower_yellow, upper_yellow)\n",
        "    # Encontrar contornos\n",
        "    contours, _ = cv2.findContours(mask, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
        "    return contours\n",
        "\n",
        "def create_annotation_from_contours(contours, image_id, filename):\n",
        "    annotations = {}\n",
        "    for i, contour in enumerate(contours):\n",
        "        segmentation = contour.flatten().tolist()\n",
        "        x, y, w, h = cv2.boundingRect(contour)\n",
        "        area = cv2.contourArea(contour)\n",
        "        annotation = {\n",
        "            'shape_attributes': {\n",
        "                'name': 'polygon',\n",
        "                'all_points_x': [int(point[0]) for point in contour],\n",
        "                'all_points_y': [int(point[1]) for point in contour]\n",
        "            },\n",
        "            'region_attributes': {}\n",
        "        }\n",
        "        annotations[str(i)] = annotation\n",
        "    return {\n",
        "        filename + str(image_id): {\n",
        "            'fileref': '',\n",
        "            'size': os.path.getsize(image_path),\n",
        "            'filename': filename,\n",
        "            'base64_img_data': '',\n",
        "            'file_attributes': {},\n",
        "            'regions': annotations\n",
        "        }\n",
        "    }\n",
        "\n",
        "def process_images(image_list, source_dir, output_json_path):\n",
        "    all_annotations = {}\n",
        "    for image_id, image_name in enumerate(image_list):\n",
        "        image_path = os.path.join(source_dir, image_name)\n",
        "        contours = find_contours(image_path)\n",
        "        annotations = create_annotation_from_contours(contours, image_id, image_name)\n",
        "        all_annotations.update(annotations)\n",
        "    with open(output_json_path, 'w') as f:\n",
        "        json.dump(all_annotations, f)\n",
        "\n",
        "# Procesar imágenes de train, val y test\n",
        "process_images(train_images, train_dir, os.path.join(destination_base_dir, 'train_annotations.json'))\n",
        "process_images(val_images, val_dir, os.path.join(destination_base_dir, 'val_annotations.json'))\n",
        "process_images(test_images, test_dir, os.path.join(destination_base_dir, 'test_annotations.json'))\n",
        "\n",
        "print(\"Generación de archivos JSON completada.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 810
        },
        "id": "fTIgMyuKwdc7",
        "outputId": "79cfb35b-247d-4a52-e9b4-ef6ff36ddd06"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "only length-1 arrays can be converted to Python scalars",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-5-62018848a66a>\u001b[0m in \u001b[0;36m<cell line: 56>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     54\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     55\u001b[0m \u001b[0;31m# Procesar imágenes de train, val y test\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 56\u001b[0;31m \u001b[0mprocess_images\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_images\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_dir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdestination_base_dir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'train_annotations.json'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     57\u001b[0m \u001b[0mprocess_images\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mval_images\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_dir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdestination_base_dir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'val_annotations.json'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m \u001b[0mprocess_images\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_images\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_dir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdestination_base_dir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'test_annotations.json'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-5-62018848a66a>\u001b[0m in \u001b[0;36mprocess_images\u001b[0;34m(image_list, source_dir, output_json_path)\u001b[0m\n\u001b[1;32m     48\u001b[0m         \u001b[0mimage_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msource_dir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimage_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     49\u001b[0m         \u001b[0mcontours\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfind_contours\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 50\u001b[0;31m         \u001b[0mannotations\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcreate_annotation_from_contours\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcontours\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimage_id\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimage_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     51\u001b[0m         \u001b[0mall_annotations\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mannotations\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     52\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput_json_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'w'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-5-62018848a66a>\u001b[0m in \u001b[0;36mcreate_annotation_from_contours\u001b[0;34m(contours, image_id, filename)\u001b[0m\n\u001b[1;32m     26\u001b[0m             'shape_attributes': {\n\u001b[1;32m     27\u001b[0m                 \u001b[0;34m'name'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m'polygon'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 28\u001b[0;31m                 \u001b[0;34m'all_points_x'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpoint\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mpoint\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mcontour\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     29\u001b[0m                 \u001b[0;34m'all_points_y'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpoint\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mpoint\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mcontour\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m             },\n",
            "\u001b[0;32m<ipython-input-5-62018848a66a>\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     26\u001b[0m             'shape_attributes': {\n\u001b[1;32m     27\u001b[0m                 \u001b[0;34m'name'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m'polygon'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 28\u001b[0;31m                 \u001b[0;34m'all_points_x'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpoint\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mpoint\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mcontour\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     29\u001b[0m                 \u001b[0;34m'all_points_y'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpoint\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mpoint\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mcontour\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m             },\n",
            "\u001b[0;31mTypeError\u001b[0m: only length-1 arrays can be converted to Python scalars"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import cv2\n",
        "import numpy as np\n",
        "\n",
        "def convert_yellow_to_black(image_path, output_path):\n",
        "    # Cargar la imagen\n",
        "    image = cv2.imread(image_path)\n",
        "\n",
        "    # Convertir la imagen al espacio de color HSV\n",
        "    hsv = cv2.cvtColor(image, cv2.COLOR_BGR2HSV)\n",
        "\n",
        "    # Definir el rango de color amarillo en HSV\n",
        "    lower_yellow = np.array([20, 100, 100])\n",
        "    upper_yellow = np.array([30, 255, 255])\n",
        "\n",
        "    # Crear una máscara para detectar el color amarillo\n",
        "    mask = cv2.inRange(hsv, lower_yellow, upper_yellow)\n",
        "\n",
        "    # Crear una imagen en blanco (255) con las mismas dimensiones que la máscara\n",
        "    result = np.ones_like(mask) * 255\n",
        "\n",
        "    # Los píxeles amarillos en la máscara se convierten en negros (0) en la imagen resultante\n",
        "    result[mask == 255] = 0\n",
        "\n",
        "    # Guardar la imagen resultante\n",
        "    cv2.imwrite(output_path, result)\n",
        "\n",
        "# Ruta de la imagen de prueba\n",
        "image_path = '/content/Dataset/Polipos/TrainValTest/test/100H0013.jpg'\n",
        "\n",
        "# Ruta de salida para la imagen resultante\n",
        "output_path = '/content/prueba.jpg'\n",
        "\n",
        "# Convertir los píxeles amarillos a negros y guardar la imagen\n",
        "convert_yellow_to_black(image_path, output_path)\n",
        "\n",
        "print(f\"Imagen guardada en: {output_path}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rG0V9iQpzXjq",
        "outputId": "b7477c49-a3a5-4f67-92d0-950373c38366"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Imagen guardada en: /content/prueba.jpg\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import cv2\n",
        "import numpy as np\n",
        "\n",
        "def convert_red_vertices_to_black(image_path, output_path):\n",
        "    # Cargar la imagen\n",
        "    image = cv2.imread(image_path)\n",
        "\n",
        "    # Convertir la imagen al espacio de color HSV\n",
        "    hsv = cv2.cvtColor(image, cv2.COLOR_BGR2HSV)\n",
        "\n",
        "    # Definir el rango de color rojo en HSV\n",
        "    lower_red1 = np.array([0, 100, 100])\n",
        "    upper_red1 = np.array([10, 255, 255])\n",
        "    lower_red2 = np.array([160, 100, 100])\n",
        "    upper_red2 = np.array([180, 255, 255])\n",
        "\n",
        "\n",
        "    # Crear una máscara para detectar el color rojo\n",
        "    mask1 = cv2.inRange(hsv, lower_red1, upper_red1)\n",
        "    mask2 = cv2.inRange(hsv, lower_red2, upper_red2)\n",
        "    mask = cv2.bitwise_or(mEntendido, puedo hacer eso. Aquí tienes cómo puedes hacerlo:\n",
        "\n",
        "python\n",
        "\n",
        "import cv2\n",
        "import numpy as np\n",
        "\n",
        "def detect_and_draw_red_vertices(image_path, output_path, distance_threshold=10):\n",
        "    # Cargar la imagen\n",
        "    image = cv2.imread(image_path)\n",
        "\n",
        "    # Convertir la imagen al espacio de color HSV\n",
        "    hsv = cv2.cvtColor(image, cv2.COLOR_BGR2HSV)\n",
        "\n",
        "    # Definir el rango de color amarillo en HSV\n",
        "    lower_yellow = np.array([20, 100, 100])\n",
        "    upper_yellow = np.array([30, 255, 255])\n",
        "\n",
        "    # Crear una máscara para detectar el color amarillo\n",
        "    mask_yellow = cv2.inRange(hsv, lower_yellow, upper_yellow)\n",
        "\n",
        "    # Obtener las posiciones de los píxeles amarillos\n",
        "    yellow_pixels = np.argwhere(mask_yellow == 255)\n",
        "\n",
        "    # Definir el rango de color rojo en HSV\n",
        "    lower_red = np.array([0, 240, 2])\n",
        "    upper_red = np.array([10, 255, 255])\n",
        "\n",
        "    # Crear una máscara para detectar el color rojo\n",
        "    mask_red = cv2.inRange(hsv, lower_red, upper_red)\n",
        "\n",
        "    # Obtener las posiciones de los píxeles rojos\n",
        "    red_pixels = np.argwhere(mask_red == 255)\n",
        "\n",
        "    # Crear una imagen en blanco (255) con las mismas dimensiones que la imagen original\n",
        "    result = np.ones_like(image) * 255\n",
        "\n",
        "    # Iterar sobre los píxeles rojos y pintar en\n",
        "print(f\"Imagen guardada en: {output_path}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 474
        },
        "id": "Bx-Hc98G1Xi6",
        "outputId": "62a32359-7eb3-438c-d257-4704ccbeecf1"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "error",
          "ename": "error",
          "evalue": "OpenCV(4.8.0) :-1: error: (-5:Bad argument) in function 'bitwise_or'\n> Overload resolution failed:\n>  - bitwise_or() missing required argument 'src2' (pos 2)\n>  - bitwise_or() missing required argument 'src2' (pos 2)\n",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31merror\u001b[0m                                     Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-5-3fd0e63846b1>\u001b[0m in \u001b[0;36m<cell line: 40>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     38\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m \u001b[0;31m# Convertir los píxeles rojos a negros y guardar la imagen\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 40\u001b[0;31m \u001b[0mconvert_red_vertices_to_black\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     41\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Imagen guardada en: {output_path}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-5-3fd0e63846b1>\u001b[0m in \u001b[0;36mconvert_red_vertices_to_black\u001b[0;34m(image_path, output_path)\u001b[0m\n\u001b[1;32m     21\u001b[0m     \u001b[0;31m# mask2 = cv2.inRange(hsv, lower_red2, upper_red2)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m     \u001b[0;31m# mask = cv2.bitwise_or(mask1, mask2)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 23\u001b[0;31m     \u001b[0mmask\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbitwise_or\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmask1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     24\u001b[0m     \u001b[0;31m# Crear una imagen en blanco (255) con las mismas dimensiones que la máscara\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m     \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mones_like\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmask\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;36m255\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31merror\u001b[0m: OpenCV(4.8.0) :-1: error: (-5:Bad argument) in function 'bitwise_or'\n> Overload resolution failed:\n>  - bitwise_or() missing required argument 'src2' (pos 2)\n>  - bitwise_or() missing required argument 'src2' (pos 2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import cv2\n",
        "import numpy as np\n",
        "\n",
        "def convert_custom_red_to_black(image_path, output_path):\n",
        "    # Cargar la imagen\n",
        "    image = cv2.imread(image_path)\n",
        "\n",
        "    # Convertir la imagen al espacio de color HSV\n",
        "    hsv = cv2.cvtColor(image, cv2.COLOR_BGR2HSV)\n",
        "\n",
        "    # Definir el nuevo rango de color rojo en HSV\n",
        "    lower_red = np.array([0, 240, 2])\n",
        "    upper_red = np.array([10, 255, 255])\n",
        "\n",
        "    # Crear una máscara para detectar el color rojo\n",
        "    mask = cv2.inRange(hsv, lower_red, upper_red)\n",
        "\n",
        "    # Crear una imagen en blanco (255) con las mismas dimensiones que la máscara\n",
        "    result = np.ones_like(mask) * 255\n",
        "\n",
        "    # Los píxeles rojos en la máscara se convierten en negros (0) en la imagen resultante\n",
        "    result[mask == 255] = 0\n",
        "\n",
        "    # Guardar la imagen resultante\n",
        "    cv2.imwrite(output_path, result)\n",
        "\n",
        "# Ruta de la imagen de prueba\n",
        "image_path = '/content/Dataset/Polipos/TrainValTest/test/100H0027.jpg'\n",
        "\n",
        "# Ruta de salida para la imagen resultante\n",
        "output_path = '/content/prueba27.jpg'\n",
        "\n",
        "# Convertir los píxeles rojos a negros y guardar la imagen\n",
        "convert_custom_red_to_black(image_path, output_path)\n",
        "\n",
        "print(f\"Imagen guardada en: {output_path}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NKuy9DlR3fnF",
        "outputId": "8353b684-5941-4e9c-f944-bf9c916db2cb"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Imagen guardada en: /content/prueba27.jpg\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import cv2\n",
        "import numpy as np\n",
        "\n",
        "def detect_and_draw_red_vertices(image_path, output_path):\n",
        "    # Cargar la imagen\n",
        "    image = cv2.imread(image_path)\n",
        "\n",
        "    # Convertir la imagen al espacio de color HSV\n",
        "    hsv = cv2.cvtColor(image, cv2.COLOR_BGR2HSV)\n",
        "\n",
        "    # Definir el rango de color rojo en HSV\n",
        "    lower_red = np.array([0, 240, 2])\n",
        "    upper_red = np.array([10, 255, 255])\n",
        "\n",
        "    # Crear una máscara para detectar el color rojo\n",
        "    mask = cv2.inRange(hsv, lower_red, upper_red)\n",
        "\n",
        "    # Encontrar los contornos de los puntos rojos\n",
        "    contours, _ = cv2.findContours(mask, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
        "\n",
        "    # Crear una imagen en blanco (255) con las mismas dimensiones que la imagen original\n",
        "    result = np.ones_like(image) * 255\n",
        "\n",
        "    # Dibujar los contornos de los puntos rojos en negro (0) en la imagen resultante\n",
        "    cv2.drawContours(result, contours, -1, (0, 0, 0), thickness=cv2.FILLED)\n",
        "\n",
        "    # Guardar la imagen resultante\n",
        "    cv2.imwrite(output_path, result)\n",
        "\n",
        "# Ruta de la imagen de prueba\n",
        "image_path = '/content/Dataset/Polipos/TrainValTest/test/100H0027.jpg'\n",
        "\n",
        "# Ruta de salida para la imagen resultante\n",
        "output_path = '/content/prueba_V2_27.jpg'\n",
        "\n",
        "# Detectar y dibujar los puntos rojos como vértices en negro y guardar la imagen\n",
        "detect_and_draw_red_vertices(image_path, output_path)\n",
        "\n",
        "print(f\"Imagen guardada en: {output_path}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eDTvxVqp43xP",
        "outputId": "138dadd0-5473-4060-80a4-802644238ba5"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Imagen guardada en: /content/prueba_V2_27.jpg\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import cv2\n",
        "import numpy as np\n",
        "\n",
        "def detect_and_draw_red_vertices(image_path, output_path):\n",
        "    # Cargar la imagen\n",
        "    image = cv2.imread(image_path)\n",
        "\n",
        "    # Convertir la imagen al espacio de color HSV\n",
        "    hsv = cv2.cvtColor(image, cv2.COLOR_BGR2HSV)\n",
        "\n",
        "    # Definir el rango de color rojo en HSV\n",
        "    lower_red = np.array([0, 240, 2])\n",
        "    upper_red = np.array([10, 255, 255])\n",
        "\n",
        "    # Crear una máscara para detectar el color rojo\n",
        "    mask = cv2.inRange(hsv, lower_red, upper_red)\n",
        "\n",
        "    # Aplicar una operación de dilatación para resaltar las regiones de píxeles rojos\n",
        "    kernel = np.ones((5,5), np.uint8)\n",
        "    dilated_mask = cv2.dilate(mask, kernel, iterations=1)\n",
        "\n",
        "    # Aplicar una operación de erosión para reducir el tamaño de las regiones resaltadas\n",
        "    eroded_mask = cv2.erode(dilated_mask, kernel, iterations=1)\n",
        "\n",
        "    # Encontrar los contornos de los puntos rojos\n",
        "    contours, _ = cv2.findContours(eroded_mask, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
        "\n",
        "    # Crear una imagen en blanco (255) con las mismas dimensiones que la imagen original\n",
        "    result = np.ones_like(image) * 255\n",
        "\n",
        "    # Dibujar los contornos de los puntos rojos en negro (0) en la imagen resultante\n",
        "    cv2.drawContours(result, contours, -1, (0, 0, 0), thickness=cv2.FILLED)\n",
        "\n",
        "    # Guardar la imagen resultante\n",
        "    cv2.imwrite(output_path, result)\n",
        "\n",
        "# Ruta de la imagen de prueba\n",
        "image_path = '/content/Dataset/Polipos/TrainValTest/test/100H0027.jpg'\n",
        "\n",
        "# Ruta de salida para la imagen resultante\n",
        "output_path = '/content/prueba_V3_27.jpg'\n",
        "\n",
        "# Detectar y dibujar los puntos rojos como vértices en negro y guardar la imagen\n",
        "detect_and_draw_red_vertices(image_path, output_path)\n",
        "\n",
        "print(f\"Imagen guardada en: {output_path}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1hOEr2f75QFD",
        "outputId": "2308f6bc-a9b6-4847-bfd4-511722f215fa"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Imagen guardada en: /content/prueba_V3_27.jpg\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import cv2\n",
        "import numpy as np\n",
        "\n",
        "def detect_and_draw_circular_vertices(image_path, output_path, min_radius=5, max_radius=20):\n",
        "    # Cargar la imagen\n",
        "    image = cv2.imread(image_path)\n",
        "\n",
        "    # Convertir la imagen al espacio de color HSV\n",
        "    hsv = cv2.cvtColor(image, cv2.COLOR_BGR2HSV)\n",
        "\n",
        "    # Definir el rango de color rojo en HSV\n",
        "    lower_red = np.array([0, 240, 2])\n",
        "    upper_red = np.array([10, 255, 255])\n",
        "\n",
        "    # Crear una máscara para detectar el color rojo\n",
        "    mask = cv2.inRange(hsv, lower_red, upper_red)\n",
        "\n",
        "    # Aplicar una operación de dilatación para resaltar las regiones de píxeles rojos\n",
        "    kernel = np.ones((5,5), np.uint8)\n",
        "    dilated_mask = cv2.dilate(mask, kernel, iterations=1)\n",
        "\n",
        "    # Aplicar una operación de erosión para reducir el tamaño de las regiones resaltadas\n",
        "    eroded_mask = cv2.erode(dilated_mask, kernel, iterations=1)\n",
        "\n",
        "    # Detectar círculos en la máscara erosionada usando la transformada de Hough para círculos\n",
        "    circles = cv2.HoughCircles(eroded_mask, cv2.HOUGH_GRADIENT, dp=1, minDist=20, param1=50, param2=30, minRadius=min_radius, maxRadius=max_radius)\n",
        "\n",
        "    # Crear una imagen en blanco (255) con las mismas dimensiones que la imagen original\n",
        "    result = np.ones_like(image) * 255\n",
        "\n",
        "    if circles is not None:\n",
        "        circles = np.round(circles[0, :]).astype(\"int\")\n",
        "\n",
        "        # Iterar sobre todos los círculos detectados\n",
        "        for (x, y, r) in circles:\n",
        "            # Verificar si el círculo es casi redondo (radio dentro del rango específico)\n",
        "            if min_radius <= r <= max_radius:\n",
        "                # Dibujar el círculo en negro (0) en la imagen resultante\n",
        "                cv2.circle(result, (x, y), r, (0, 0, 0), thickness=cv2.FILLED)\n",
        "\n",
        "    # Guardar la imagen resultante\n",
        "    cv2.imwrite(output_path, result)\n",
        "\n",
        "# Ruta de la imagen de prueba\n",
        "image_path = '/content/Dataset/Polipos/TrainValTest/test/100H0027.jpg'\n",
        "\n",
        "# Ruta de salida para la imagen resultante\n",
        "output_path = '/content/prueba_V4_27.jpg'\n",
        "\n",
        "# Detectar y dibujar círculos como vértices en negro y guardar la imagen\n",
        "detect_and_draw_circular_vertices(image_path, output_path)\n",
        "\n",
        "print(f\"Imagen guardada en: {output_path}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_fmCjq-_5nBp",
        "outputId": "06a22c73-0ef6-4e97-fd48-9e673ee46cfc"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Imagen guardada en: /content/prueba_V4_27.jpg\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import cv2\n",
        "import numpy as np\n",
        "\n",
        "def detect_and_draw_circular_vertices(image_path, output_path, min_radius=5, max_radius=20, dp=1, min_dist=20, param1=50, param2=30):\n",
        "    # Cargar la imagen\n",
        "    image = cv2.imread(image_path)\n",
        "\n",
        "    # Convertir la imagen al espacio de color HSV\n",
        "    hsv = cv2.cvtColor(image, cv2.COLOR_BGR2HSV)\n",
        "\n",
        "    # Definir el rango de color rojo en HSV\n",
        "    lower_red = np.array([0, 240, 2])\n",
        "    upper_red = np.array([10, 255, 255])\n",
        "\n",
        "    # Crear una máscara para detectar el color rojo\n",
        "    mask = cv2.inRange(hsv, lower_red, upper_red)\n",
        "\n",
        "    # Aplicar una operación de dilatación para resaltar las regiones de píxeles rojos\n",
        "    kernel = np.ones((5,5), np.uint8)\n",
        "    dilated_mask = cv2.dilate(mask, kernel, iterations=1)\n",
        "\n",
        "    # Aplicar una operación de erosión para reducir el tamaño de las regiones resaltadas\n",
        "    eroded_mask = cv2.erode(dilated_mask, kernel, iterations=1)\n",
        "\n",
        "    # Detectar círculos en la máscara erosionada usando la transformada de Hough para círculos\n",
        "    circles = cv2.HoughCircles(eroded_mask, cv2.HOUGH_GRADIENT, dp=dp, minDist=min_dist, param1=param1, param2=param2, minRadius=min_radius, maxRadius=max_radius)\n",
        "\n",
        "    # Crear una imagen en blanco (255) con las mismas dimensiones que la imagen original\n",
        "    result = np.ones_like(image) * 255\n",
        "\n",
        "    if circles is not None:\n",
        "        circles = np.round(circles[0, :]).astype(\"int\")\n",
        "\n",
        "        # Iterar sobre todos los círculos detectados\n",
        "        for (x, y, r) in circles:\n",
        "            # Verificar si el círculo es casi redondo (radio dentro del rango específico)\n",
        "            if min_radius <= r <= max_radius:\n",
        "                # Dibujar el círculo en negro (0) en la imagen resultante\n",
        "                cv2.circle(result, (x, y), r, (0, 0, 0), thickness=cv2.FILLED)\n",
        "\n",
        "    # Guardar la imagen resultante\n",
        "    cv2.imwrite(output_path, result)\n",
        "\n",
        "# Ruta de la imagen de prueba\n",
        "image_path = '/content/Dataset/Polipos/TrainValTest/test/100H0027.jpg'\n",
        "\n",
        "# Ruta de salida para la imagen resultante\n",
        "output_path = '/content/prueba_V5_27.jpg'\n",
        "\n",
        "\n",
        "# Detectar y dibujar círculos como vértices en negro y guardar la imagen\n",
        "detect_and_draw_circular_vertices(image_path, output_path)\n",
        "\n",
        "print(f\"Imagen guardada en: {output_path}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KLC7F8xj58x5",
        "outputId": "cf78cae4-b8d5-436d-b878-1daee67587d0"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Imagen guardada en: /content/prueba_V5_27.jpg\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import cv2\n",
        "import numpy as np\n",
        "\n",
        "def detect_and_draw_red_vertices(image_path, output_path):\n",
        "    # Cargar la imagen\n",
        "    image = cv2.imread(image_path)\n",
        "\n",
        "    # Convertir la imagen al espacio de color HSV\n",
        "    hsv = cv2.cvtColor(image, cv2.COLOR_BGR2HSV)\n",
        "\n",
        "    # Definir el rango de color rojo en HSV\n",
        "    lower_red = np.array([0, 240, 2])\n",
        "    upper_red = np.array([10, 255, 255])\n",
        "\n",
        "    # Crear una máscara para detectar el color rojo\n",
        "    mask_red = cv2.inRange(hsv, lower_red, upper_red)\n",
        "\n",
        "    # Aplicar una operación de dilatación para resaltar las regiones de píxeles rojos\n",
        "    kernel = np.ones((5,5), np.uint8)\n",
        "    dilated_mask_red = cv2.dilate(mask_red, kernel, iterations=1)\n",
        "\n",
        "    # Aplicar una operación de erosión para reducir el tamaño de las regiones resaltadas\n",
        "    eroded_mask_red = cv2.erode(dilated_mask_red, kernel, iterations=1)\n",
        "\n",
        "    # Encontrar los contornos de los puntos rojos\n",
        "    _, contours_red, _ = cv2.findContours(eroded_mask_red, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
        "\n",
        "    # Crear una máscara para detectar el color amarillo\n",
        "    lower_yellow = np.array([20, 100, 100])\n",
        "    upper_yellow = np.array([30, 255, 255])\n",
        "    mask_yellow = cv2.inRange(hsv, lower_yellow, upper_yellow)\n",
        "\n",
        "    # Detectar los bordes de color amarillo\n",
        "    edges_yellow = cv2.Canny(mask_yellow, 50, 150, apertureSize=3)\n",
        "\n",
        "    # Aplicar una operación de dilatación para resaltar los bordes\n",
        "    dilated_edges_yellow = cv2.dilate(edges_yellow, kernel, iterations=1)\n",
        "\n",
        "    # Crear una imagen en blanco (255) con las mismas dimensiones que la imagen original\n",
        "    result = np.ones_like(image) * 255\n",
        "\n",
        "    # Dibujar los contornos de los puntos rojos en la imagen resultante\n",
        "    cv2.drawContours(result, contours_red, -1, (0, 0, 0), thickness=cv2.FILLED)\n",
        "\n",
        "    # Aplicar la máscara de bordes amarillos al área alrededor de los contornos rojos\n",
        "    result[dilated_edges_yellow == 255] = 255\n",
        "\n",
        "    # Guardar la imagen resultante\n",
        "    cv2.imwrite(output_path, result)\n",
        "\n",
        "# Ruta de la imagen de prueba\n",
        "image_path = '/content/Dataset/Polipos/TrainValTest/test/100H0027.jpg'\n",
        "\n",
        "# Ruta de salida para la imagen resultante\n",
        "output_path = '/content/prueba_Aristas_27.jpg'\n",
        "\n",
        "# Detectar y dibujar los puntos rojos como vértices en negro y guardar la imagen\n",
        "detect_and_draw_red_vertices(image_path, output_path)\n",
        "\n",
        "print(f\"Imagen guardada en: {output_path}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 422
        },
        "id": "7PRkVL7n607j",
        "outputId": "7f0096bd-a787-4bb4-a9ff-c76e12ab2815"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "not enough values to unpack (expected 3, got 2)",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-14-b5f1711b4744>\u001b[0m in \u001b[0;36m<cell line: 58>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     56\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m \u001b[0;31m# Detectar y dibujar los puntos rojos como vértices en negro y guardar la imagen\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 58\u001b[0;31m \u001b[0mdetect_and_draw_red_vertices\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     59\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     60\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Imagen guardada en: {output_path}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-14-b5f1711b4744>\u001b[0m in \u001b[0;36mdetect_and_draw_red_vertices\u001b[0;34m(image_path, output_path)\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m     \u001b[0;31m# Encontrar los contornos de los puntos rojos\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 26\u001b[0;31m     \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcontours_red\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfindContours\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0meroded_mask_red\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mRETR_EXTERNAL\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCHAIN_APPROX_SIMPLE\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     27\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m     \u001b[0;31m# Crear una máscara para detectar el color amarillo\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: not enough values to unpack (expected 3, got 2)"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import cv2\n",
        "import numpy as np\n",
        "\n",
        "def detect_and_draw_red_vertices(image_path, output_path, distance_threshold=10):\n",
        "    # Cargar la imagen\n",
        "    image = cv2.imread(image_path)\n",
        "\n",
        "    # Convertir la imagen al espacio de color HSV\n",
        "    hsv = cv2.cvtColor(image, cv2.COLOR_BGR2HSV)\n",
        "\n",
        "    # Definir el rango de color amarillo en HSV\n",
        "    lower_yellow = np.array([20, 100, 100])\n",
        "    upper_yellow = np.array([30, 255, 255])\n",
        "\n",
        "    # Crear una máscara para detectar el color amarillo\n",
        "    mask_yellow = cv2.inRange(hsv, lower_yellow, upper_yellow)\n",
        "\n",
        "    # Obtener las posiciones de los píxeles amarillos\n",
        "    yellow_pixels = np.argwhere(mask_yellow == 255)\n",
        "\n",
        "    # Definir el rango de color rojo en HSV\n",
        "    lower_red = np.array([0, 240, 2])\n",
        "    upper_red = np.array([10, 255, 255])\n",
        "\n",
        "    # Crear una máscara para detectar el color rojo\n",
        "    mask_red = cv2.inRange(hsv, lower_red, upper_red)\n",
        "\n",
        "    # Obtener las posiciones de los píxeles rojos\n",
        "    red_pixels = np.argwhere(mask_red == 255)\n",
        "\n",
        "    # Crear una imagen en blanco (255) con las mismas dimensiones que la imagen original\n",
        "    result = np.ones_like(image) * 255\n",
        "\n",
        "    # Iterar sobre los píxeles rojos y pintar en negro si están cerca de los píxeles amarillos\n",
        "    for red_pixel in red_pixels:\n",
        "        for yellow_pixel in yellow_pixels:\n",
        "            distance = np.linalg.norm(red_pixel - yellow_pixel)\n",
        "            if distance <= distance_threshold:\n",
        "                result[red_pixel[0], red_pixel[1]] = [0, 0, 0]\n",
        "                break  # Salir del bucle interno si el píxel rojo está cerca de algún píxel amarillo\n",
        "\n",
        "    # Guardar la imagen resultante\n",
        "    cv2.imwrite(output_path, result)\n",
        "\n",
        "# Ruta de la imagen de prueba\n",
        "image_path = '/content/Dataset/Polipos/TrainValTest/test/100H0027.jpg'\n",
        "\n",
        "# Ruta de salida para la imagen resultante\n",
        "output_path = '/content/prueba_Aristas_V2_27.jpg'\n",
        "\n",
        "# Distancia máxima para considerar que un píxel rojo está cerca de un píxel amarillo\n",
        "distance_threshold = 10\n",
        "\n",
        "# Detectar y dibujar los puntos rojos como vértices en negro y guardar la imagen\n",
        "detect_and_draw_red_vertices(image_path, output_path, distance_threshold)\n",
        "\n",
        "print(f\"Imagen guardada en: {output_path}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AeJlH37a7zlE",
        "outputId": "02690b80-b565-43ea-d94d-08e4f2f3d01a"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Imagen guardada en: /content/prueba_Aristas_V2_27.jpg\n"
          ]
        }
      ]
    }
  ]
}