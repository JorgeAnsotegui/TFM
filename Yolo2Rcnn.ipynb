{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMpWVURG9TFpYepRVI6HIn9",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/JorgeAnsotegui/TFM/blob/main/Yolo2Rcnn.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u_qwPFlZruwS",
        "outputId": "686c6581-a361-42dc-b2ef-c22cfcec04e4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "# Conectar Colab a Google Drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import random\n",
        "import shutil\n",
        "import json\n",
        "\n",
        "# Rutas de las carpetas de imágenes y etiquetas originales\n",
        "images_dir = \"/content/drive/MyDrive/TFM/dataset_Jorge_V2/train/images\"\n",
        "labels_dir = \"/content/drive/MyDrive/TFM/dataset_Jorge_V2/train/labels\"\n",
        "\n",
        "# Ruta principal del dataset final\n",
        "main_dir = \"/content/dataset_MaskRCNN\"\n",
        "\n",
        "# Subcarpetas del dataset final\n",
        "train_dir = os.path.join(main_dir, \"train\")\n",
        "test_dir = os.path.join(main_dir, \"test\")\n",
        "val_dir = os.path.join(main_dir, \"val\")\n",
        "\n",
        "# Rutas de las carpetas de train, test y val para imágenes y etiquetas\n",
        "train_images_dir = os.path.join(train_dir, \"images\")\n",
        "train_labels_dir = os.path.join(train_dir, \"labels\")\n",
        "test_images_dir = os.path.join(test_dir, \"images\")\n",
        "test_labels_dir = os.path.join(test_dir, \"labels\")\n",
        "val_images_dir = os.path.join(val_dir, \"images\")\n",
        "val_labels_dir = os.path.join(val_dir, \"labels\")\n",
        "\n",
        "# Función para crear carpetas si no existen\n",
        "def create_directories_if_not_exist(*directories):\n",
        "    for directory in directories:\n",
        "        os.makedirs(directory, exist_ok=True)\n",
        "\n",
        "# Crear carpetas de train, test y val si no existen\n",
        "create_directories_if_not_exist(train_dir, test_dir, val_dir)\n",
        "create_directories_if_not_exist(train_images_dir, train_labels_dir, test_images_dir, test_labels_dir, val_images_dir, val_labels_dir)\n",
        "\n",
        "# Proporciones para train, test y val\n",
        "train_percent = 0.6\n",
        "test_percent = 0.2\n",
        "val_percent = 0.2\n",
        "\n",
        "# Obtener lista de nombres de archivos de imágenes\n",
        "image_files = os.listdir(images_dir)\n",
        "# Filtrar solo los archivos con extensión .jpg\n",
        "image_files = [file for file in image_files if file.endswith(\".jpg\")]\n",
        "\n",
        "# Barajar la lista de nombres de archivos\n",
        "random.shuffle(image_files)\n",
        "\n",
        "# Calcular el número de archivos para cada conjunto\n",
        "total_images = len(image_files)\n",
        "num_train = int(total_images * train_percent)\n",
        "num_test = int(total_images * test_percent)\n",
        "num_val = total_images - num_train - num_test\n",
        "\n",
        "# Dividir la lista de nombres de archivos en train, test y val\n",
        "train_images = image_files[:num_train]\n",
        "test_images = image_files[num_train:num_train+num_test]\n",
        "val_images = image_files[num_train+num_test:]\n",
        "\n",
        "# Crear carpetas de train, test y val si no existen\n",
        "os.makedirs(train_images_dir, exist_ok=True)\n",
        "os.makedirs(train_labels_dir, exist_ok=True)\n",
        "os.makedirs(test_images_dir, exist_ok=True)\n",
        "os.makedirs(test_labels_dir, exist_ok=True)\n",
        "os.makedirs(val_images_dir, exist_ok=True)\n",
        "os.makedirs(val_labels_dir, exist_ok=True)\n",
        "\n",
        "# Copiar imágenes y etiquetas a las carpetas correspondientes\n",
        "def copy_files(files, source_dir, dest_images_dir, dest_labels_dir):\n",
        "    for file in files:\n",
        "        # Copiar imágenes\n",
        "        shutil.copy(os.path.join(source_dir, file), dest_images_dir)\n",
        "        # Copiar etiquetas\n",
        "        label_file = os.path.splitext(file)[0] + \".txt\"\n",
        "        shutil.copy(os.path.join(labels_dir, label_file), dest_labels_dir)\n",
        "\n",
        "copy_files(train_images, images_dir, train_images_dir, train_labels_dir)\n",
        "copy_files(test_images, images_dir, test_images_dir, test_labels_dir)\n",
        "copy_files(val_images, images_dir, val_images_dir, val_labels_dir)\n",
        "\n",
        "print(\"División de imágenes y etiquetas completada.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KxXtCqI33o82",
        "outputId": "e9e78231-0b50-43bd-8863-1613875ba757"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "División de imágenes y etiquetas completada.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Definimos las funciones de lectura y cambio de formato de las etiquetas"
      ],
      "metadata": {
        "id": "3aqlk2cHvnDn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def read_yolo_labels(yolo_label_dir):\n",
        "    \"\"\"Función para leer archivos .txt de etiquetas de YOLO.\"\"\"\n",
        "    yolo_labels = {}\n",
        "    for file_name in os.listdir(yolo_label_dir):\n",
        "        if file_name.endswith(\".txt\"):\n",
        "            with open(os.path.join(yolo_label_dir, file_name), \"r\") as f:\n",
        "                content = f.read().strip().split(\"\\n\")\n",
        "                labels = []\n",
        "                for line in content:\n",
        "                    parts = line.split(\" \")\n",
        "                    class_id = int(parts[0])\n",
        "                    points = []\n",
        "                    for i in range(1, len(parts), 2):\n",
        "                        x, y = map(float, parts[i:i+2])\n",
        "                        point = [x, y]\n",
        "                        points.append(point)\n",
        "                    label = {\"class_id\": class_id, \"points\": points}\n",
        "                    labels.append(label)\n",
        "                yolo_labels[file_name] = labels\n",
        "    return yolo_labels\n",
        "\n",
        "def convert_to_mask_rcnn_labels(yolo_labels):\n",
        "    \"\"\"Convierte un archivo .txt de etiquetas de segmentación de Yolo en un .json de etiquetas de segmentación de Mask RCNN.\"\"\"\n",
        "    mask_rcnn_labels = {}\n",
        "    for file_name, yolo_objs in yolo_labels.items():\n",
        "        mask_rcnn_labels[file_name.replace(\".txt\", \".jpg\")] = {\n",
        "            \"fileref\": \"\",\n",
        "            \"size\": 123456,  # Tamaño de la imagen (ajustar según sea necesario)\n",
        "            \"filename\": file_name.replace(\".txt\", \".jpg\"),\n",
        "            \"base64_img_data\": \"\",\n",
        "            \"file_attributes\": {},\n",
        "            \"regions\": {}\n",
        "        }\n",
        "        for i, obj in enumerate(yolo_objs):\n",
        "            mask_rcnn_labels[file_name.replace(\".txt\", \".jpg\")][\"regions\"][str(i)] = {\n",
        "                \"shape_attributes\": {\n",
        "                    \"name\": \"polygon\",\n",
        "                    \"all_points_x\": [int(point[0] * 123) for point in obj[\"points\"]],  # Ajustar a las dimensiones de la imagen\n",
        "                    \"all_points_y\": [int(point[1] * 456) for point in obj[\"points\"]]  # Ajustar a las dimensiones de la imagen\n",
        "                },\n",
        "                \"region_attributes\": {\n",
        "                    \"class\": obj[\"class_id\"]  # Clase del objeto\n",
        "                }\n",
        "            }\n",
        "    return mask_rcnn_labels\n",
        "\n",
        "def merge_mask_rcnn_labels(input_dir, output_dir):\n",
        "    \"\"\"Se indica el directorio que contiene los .json que se quieren juntar en un solo archivo y se indica la ruta donde se quiere guardar dicho archivo.\"\"\"\n",
        "    # Verificar si el directorio de salida existe, si no, crearlo\n",
        "    os.makedirs(output_dir, exist_ok=True)\n",
        "\n",
        "    # Diccionario para almacenar todos los diccionarios de imágenes\n",
        "    merged_data = {}\n",
        "\n",
        "    # Iterar sobre cada archivo en el directorio de entrada\n",
        "    for filename in os.listdir(input_dir):\n",
        "        if filename.endswith(\".json\"):\n",
        "            filepath = os.path.join(input_dir, filename)\n",
        "            # Abrir y cargar cada archivo JSON\n",
        "            with open(filepath, \"r\") as f:\n",
        "                data = json.load(f)\n",
        "            # Extraer el nombre del archivo (sin la extensión)\n",
        "            filename_key = os.path.splitext(filename)[0]\n",
        "            # Agregar los datos de la imagen al diccionario fusionado\n",
        "            merged_data[filename_key] = data\n",
        "\n",
        "    # Escribir el diccionario fusionado en un archivo JSON en el directorio de salida\n",
        "    output_file = os.path.join(output_dir, \"merged_labels.json\")\n",
        "    with open(output_file, \"w\") as f:\n",
        "        json.dump(merged_data, f, indent=4)"
      ],
      "metadata": {
        "id": "k8st8IU1t1ab"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Leemos las etiquetas en formato YoloV9\n"
      ],
      "metadata": {
        "id": "FWmDJwosu_XC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Leer archivos de etiquetas de YOLO para train, test y val\n",
        "train_yolo_labels = read_yolo_labels(train_labels_dir)\n",
        "test_yolo_labels = read_yolo_labels(test_labels_dir)\n",
        "val_yolo_labels = read_yolo_labels(val_labels_dir)\n",
        "\n",
        "print(\"Etiquetas de YOLO leídas para train, test y val.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IIxjjvrr7lIU",
        "outputId": "e2efa6fd-7b4f-45f8-a0e2-4ab3978f0cbf"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Etiquetas de YOLO leídas para train, test y val.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Convertimos las etiquetas en formato Mask RCNN"
      ],
      "metadata": {
        "id": "3SQMSHP1vHRC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Carpeta de train\n",
        "train_mask_rcnn_labels = convert_to_mask_rcnn_labels(train_yolo_labels)\n",
        "train_RCNN_labels_dir = \"/content/dataset_MaskRCNN/train/RCNN_labels\"\n",
        "\n",
        "# Guardar los resultados en la carpeta correspondiente\n",
        "if not os.path.exists(train_RCNN_labels_dir):\n",
        "    os.makedirs(train_RCNN_labels_dir)\n",
        "\n",
        "for file_name, label_data in train_mask_rcnn_labels.items():\n",
        "    with open(os.path.join(train_RCNN_labels_dir, file_name.replace(\".jpg\", \".json\")), \"w\") as f:\n",
        "        json.dump(label_data, f)\n",
        "\n",
        "# Carpeta de test\n",
        "test_mask_rcnn_labels = convert_to_mask_rcnn_labels(test_yolo_labels)\n",
        "test_RCNN_labels_dir = \"/content/dataset_MaskRCNN/test/RCNN_labels\"\n",
        "\n",
        "# Guardar los resultados en la carpeta correspondiente\n",
        "if not os.path.exists(test_RCNN_labels_dir):\n",
        "    os.makedirs(test_RCNN_labels_dir)\n",
        "\n",
        "for file_name, label_data in test_mask_rcnn_labels.items():\n",
        "    with open(os.path.join(test_RCNN_labels_dir, file_name.replace(\".jpg\", \".json\")), \"w\") as f:\n",
        "        json.dump(label_data, f)\n",
        "\n",
        "# Carpeta de val\n",
        "val_mask_rcnn_labels = convert_to_mask_rcnn_labels(val_yolo_labels)\n",
        "val_RCNN_labels_dir = \"/content/dataset_MaskRCNN/val/RCNN_labels\"\n",
        "\n",
        "# Guardar los resultados en la carpeta correspondiente\n",
        "if not os.path.exists(val_RCNN_labels_dir):\n",
        "    os.makedirs(val_RCNN_labels_dir)\n",
        "\n",
        "for file_name, label_data in val_mask_rcnn_labels.items():\n",
        "    with open(os.path.join(val_RCNN_labels_dir, file_name.replace(\".jpg\", \".json\")), \"w\") as f:\n",
        "        json.dump(label_data, f)\n"
      ],
      "metadata": {
        "id": "-t1_cKN4Clmx"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Juntamos todas las etiquetas en un solo .json para cada carpeta de Train, Test y Val."
      ],
      "metadata": {
        "id": "Mf8xY0yRvO3z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Rutas de los directorios de train, test y val\n",
        "train_RCNN_labels_dir = \"/content/dataset_MaskRCNN/train/RCNN_labels\"\n",
        "test_RCNN_labels_dir = \"/content/dataset_MaskRCNN/test/RCNN_labels\"\n",
        "val_RCNN_labels_dir = \"/content/dataset_MaskRCNN/val/RCNN_labels\"\n",
        "\n",
        "# Rutas de los directorios de salida fusionados\n",
        "merged_train_RCNN_labels_dir = \"/content/dataset_MaskRCNN/train/RCNN_labels_merged/\"\n",
        "merged_test_RCNN_labels_dir = \"/content/dataset_MaskRCNN/test/RCNN_labels_merged/\"\n",
        "merged_val_RCNN_labels_dir = \"/content/dataset_MaskRCNN/val/RCNN_labels_merged/\"\n",
        "\n",
        "# Crear los directorios de salida si no existen\n",
        "create_directories_if_not_exist(merged_train_RCNN_labels_dir, merged_test_RCNN_labels_dir, merged_val_RCNN_labels_dir)\n",
        "\n",
        "# Llamar a la función para fusionar los archivos JSON\n",
        "merge_mask_rcnn_labels(train_RCNN_labels_dir, merged_train_RCNN_labels_dir)\n",
        "merge_mask_rcnn_labels(test_RCNN_labels_dir, merged_test_RCNN_labels_dir)\n",
        "merge_mask_rcnn_labels(val_RCNN_labels_dir, merged_val_RCNN_labels_dir)"
      ],
      "metadata": {
        "id": "B86yZOh6MYJs"
      },
      "execution_count": 6,
      "outputs": []
    }
  ]
}