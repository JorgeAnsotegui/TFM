{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOlM2Ewu4a/f0MXHEaMzLxm",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/JorgeAnsotegui/TFM/blob/main/Yolo2Rcnn.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u_qwPFlZruwS",
        "outputId": "5a6ca1bf-7b41-44d6-b5c1-2eaa372edba2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "# Conectar Colab a Google Drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import random\n",
        "import shutil\n",
        "import json\n",
        "from PIL import Image\n",
        "\n",
        "# Rutas de las carpetas de imágenes y etiquetas originales\n",
        "images_dir = \"/content/drive/MyDrive/TFM/dataset_Jorge_V2/train/images\"\n",
        "labels_dir = \"/content/drive/MyDrive/TFM/dataset_Jorge_V2/train/labels\"\n",
        "\n",
        "# Ruta principal del dataset final\n",
        "main_dir = \"/content/dataset_MaskRCNN\"\n",
        "\n",
        "# Subcarpetas del dataset final\n",
        "train_dir = os.path.join(main_dir, \"train\")\n",
        "test_dir = os.path.join(main_dir, \"test\")\n",
        "val_dir = os.path.join(main_dir, \"val\")\n",
        "\n",
        "# Rutas de las carpetas de train, test y val para imágenes y etiquetas\n",
        "train_images_dir = os.path.join(train_dir, \"images\")\n",
        "train_labels_dir = os.path.join(train_dir, \"labels\")\n",
        "test_images_dir = os.path.join(test_dir, \"images\")\n",
        "test_labels_dir = os.path.join(test_dir, \"labels\")\n",
        "val_images_dir = os.path.join(val_dir, \"images\")\n",
        "val_labels_dir = os.path.join(val_dir, \"labels\")\n",
        "\n",
        "# Función para crear carpetas si no existen\n",
        "def create_directories_if_not_exist(*directories):\n",
        "    for directory in directories:\n",
        "        os.makedirs(directory, exist_ok=True)\n",
        "\n",
        "# Crear carpetas de train, test y val si no existen\n",
        "create_directories_if_not_exist(train_dir, test_dir, val_dir)\n",
        "create_directories_if_not_exist(train_images_dir, train_labels_dir, test_images_dir, test_labels_dir, val_images_dir, val_labels_dir)\n",
        "\n",
        "# Proporciones para train, test y val\n",
        "train_percent = 0.6\n",
        "test_percent = 0.2\n",
        "val_percent = 0.2\n",
        "\n",
        "# Obtener lista de nombres de archivos de imágenes\n",
        "image_files = os.listdir(images_dir)\n",
        "# Filtrar solo los archivos con extensión .jpg\n",
        "image_files = [file for file in image_files if file.endswith(\".jpg\")]\n",
        "\n",
        "# Barajar la lista de nombres de archivos\n",
        "random.shuffle(image_files)\n",
        "\n",
        "# Calcular el número de archivos para cada conjunto\n",
        "total_images = len(image_files)\n",
        "num_train = int(total_images * train_percent)\n",
        "num_test = int(total_images * test_percent)\n",
        "num_val = total_images - num_train - num_test\n",
        "\n",
        "# Dividir la lista de nombres de archivos en train, test y val\n",
        "train_images = image_files[:num_train]\n",
        "test_images = image_files[num_train:num_train+num_test]\n",
        "val_images = image_files[num_train+num_test:]\n",
        "\n",
        "# Crear carpetas de train, test y val si no existen\n",
        "os.makedirs(train_images_dir, exist_ok=True)\n",
        "os.makedirs(train_labels_dir, exist_ok=True)\n",
        "os.makedirs(test_images_dir, exist_ok=True)\n",
        "os.makedirs(test_labels_dir, exist_ok=True)\n",
        "os.makedirs(val_images_dir, exist_ok=True)\n",
        "os.makedirs(val_labels_dir, exist_ok=True)\n",
        "\n",
        "# Copiar imágenes y etiquetas a las carpetas correspondientes\n",
        "def copy_files(files, source_dir, dest_images_dir, dest_labels_dir):\n",
        "    for file in files:\n",
        "        # Copiar imágenes\n",
        "        shutil.copy(os.path.join(source_dir, file), dest_images_dir)\n",
        "        # Copiar etiquetas\n",
        "        label_file = os.path.splitext(file)[0] + \".txt\"\n",
        "        shutil.copy(os.path.join(labels_dir, label_file), dest_labels_dir)\n",
        "\n",
        "copy_files(train_images, images_dir, train_images_dir, train_labels_dir)\n",
        "copy_files(test_images, images_dir, test_images_dir, test_labels_dir)\n",
        "copy_files(val_images, images_dir, val_images_dir, val_labels_dir)\n",
        "\n",
        "print(\"División de imágenes y etiquetas completada.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KxXtCqI33o82",
        "outputId": "253f87c5-cee7-4b31-84e5-2cb5973fc31f"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "División de imágenes y etiquetas completada.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Definimos las funciones de lectura y cambio de formato de las etiquetas"
      ],
      "metadata": {
        "id": "3aqlk2cHvnDn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def read_yolo_labels(yolo_label_dir):\n",
        "    \"\"\"Función para leer archivos .txt de etiquetas de YOLO.\"\"\"\n",
        "    yolo_labels = {}\n",
        "    for file_name in os.listdir(yolo_label_dir):\n",
        "        if file_name.endswith(\".txt\"):\n",
        "            with open(os.path.join(yolo_label_dir, file_name), \"r\") as f:\n",
        "                content = f.read().strip().split(\"\\n\")\n",
        "                labels = []\n",
        "                for line in content:\n",
        "                    parts = line.split(\" \")\n",
        "                    class_id = int(parts[0])\n",
        "                    points = []\n",
        "                    for i in range(1, len(parts), 2):\n",
        "                        x, y = map(float, parts[i:i+2])\n",
        "                        point = [x, y]\n",
        "                        points.append(point)\n",
        "                    label = {\"class_id\": class_id, \"points\": points}\n",
        "                    labels.append(label)\n",
        "                yolo_labels[file_name] = labels\n",
        "    return yolo_labels\n",
        "\n",
        "def convert_to_mask_rcnn_labels(yolo_labels, image_folder):\n",
        "    \"\"\"Convierte un archivo .txt de etiquetas de segmentación de Yolo en un .json de etiquetas de segmentación de Mask RCNN.\"\"\"\n",
        "    mask_rcnn_labels = {}\n",
        "\n",
        "    for file_name, yolo_objs in yolo_labels.items():\n",
        "        image_name = file_name.replace(\".txt\", \".jpg\")\n",
        "        image_path = os.path.join(image_folder, image_name)\n",
        "\n",
        "        # Obtener el tamaño de la imagen en bytes\n",
        "        image_size_bytes = os.path.getsize(image_path)\n",
        "\n",
        "        # Abrir la imagen para obtener el ancho y el alto\n",
        "        with Image.open(image_path) as img:\n",
        "            width, height = img.size\n",
        "\n",
        "        mask_rcnn_labels[image_name] = {\n",
        "            \"fileref\": \"\",\n",
        "            \"size\": image_size_bytes,\n",
        "            \"filename\": image_name,\n",
        "            \"base64_img_data\": \"\",\n",
        "            \"file_attributes\": {},\n",
        "            \"regions\": {}\n",
        "        }\n",
        "\n",
        "        for i, obj in enumerate(yolo_objs):\n",
        "            mask_rcnn_labels[image_name][\"regions\"][str(i)] = {\n",
        "                \"shape_attributes\": {\n",
        "                    \"name\": \"polygon\",\n",
        "                    \"all_points_x\": [int(point[0] * width) for point in obj[\"points\"]],\n",
        "                    \"all_points_y\": [int(point[1] * height) for point in obj[\"points\"]]\n",
        "                },\n",
        "                \"region_attributes\": {\n",
        "                    \"class\": obj[\"class_id\"]  # Clase del objeto\n",
        "                }\n",
        "            }\n",
        "\n",
        "    return mask_rcnn_labels\n",
        "\n",
        "def merge_mask_rcnn_labels(input_dir, output_dir):\n",
        "    \"\"\"Se indica el directorio que contiene los .json que se quieren juntar en un solo archivo y se indica la ruta donde se quiere guardar dicho archivo.\"\"\"\n",
        "    # Verificar si el directorio de salida existe, si no, crearlo\n",
        "    os.makedirs(output_dir, exist_ok=True)\n",
        "\n",
        "    # Diccionario para almacenar todos los diccionarios de imágenes\n",
        "    merged_data = {}\n",
        "\n",
        "    # Iterar sobre cada archivo en el directorio de entrada\n",
        "    for filename in os.listdir(input_dir):\n",
        "        if filename.endswith(\".json\"):\n",
        "            filepath = os.path.join(input_dir, filename)\n",
        "            # Abrir y cargar cada archivo JSON\n",
        "            with open(filepath, \"r\") as f:\n",
        "                data = json.load(f)\n",
        "            # Extraer el nombre del archivo (sin la extensión)\n",
        "            filename_key = os.path.splitext(filename)[0]\n",
        "            # Agregar los datos de la imagen al diccionario fusionado\n",
        "            merged_data[filename_key] = data\n",
        "\n",
        "    # Escribir el diccionario fusionado en un archivo JSON en el directorio de salida\n",
        "    output_file = os.path.join(output_dir, \"merged_labels.json\")\n",
        "    with open(output_file, \"w\") as f:\n",
        "        json.dump(merged_data, f, indent=4)"
      ],
      "metadata": {
        "id": "k8st8IU1t1ab"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Leemos las etiquetas en formato YoloV9\n"
      ],
      "metadata": {
        "id": "FWmDJwosu_XC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Leer archivos de etiquetas de YOLO para train, test y val\n",
        "train_yolo_labels = read_yolo_labels(train_labels_dir)\n",
        "test_yolo_labels = read_yolo_labels(test_labels_dir)\n",
        "val_yolo_labels = read_yolo_labels(val_labels_dir)\n",
        "\n",
        "print(\"Etiquetas de YOLO leídas para train, test y val.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IIxjjvrr7lIU",
        "outputId": "cadfdd45-2fa1-4f20-a867-5db47a2d11f7"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Etiquetas de YOLO leídas para train, test y val.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Convertimos las etiquetas en formato Mask RCNN"
      ],
      "metadata": {
        "id": "3SQMSHP1vHRC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Carpeta de train\n",
        "train_image_folder = \"/content/dataset_MaskRCNN/train/images\"\n",
        "train_mask_rcnn_labels = convert_to_mask_rcnn_labels(train_yolo_labels, train_image_folder)\n",
        "train_RCNN_labels_dir = \"/content/dataset_MaskRCNN/train/RCNN_labels\"\n",
        "\n",
        "# Guardar los resultados en la carpeta correspondiente\n",
        "if not os.path.exists(train_RCNN_labels_dir):\n",
        "    os.makedirs(train_RCNN_labels_dir)\n",
        "\n",
        "for file_name, label_data in train_mask_rcnn_labels.items():\n",
        "    with open(os.path.join(train_RCNN_labels_dir, file_name.replace(\".jpg\", \".json\")), \"w\") as f:\n",
        "        json.dump(label_data, f, indent=4)\n",
        "\n",
        "# Carpeta de test\n",
        "test_image_folder = \"/content/dataset_MaskRCNN/test/images\"\n",
        "test_mask_rcnn_labels = convert_to_mask_rcnn_labels(test_yolo_labels, test_image_folder)\n",
        "test_RCNN_labels_dir = \"/content/dataset_MaskRCNN/test/RCNN_labels\"\n",
        "\n",
        "# Guardar los resultados en la carpeta correspondiente\n",
        "if not os.path.exists(test_RCNN_labels_dir):\n",
        "    os.makedirs(test_RCNN_labels_dir)\n",
        "\n",
        "for file_name, label_data in test_mask_rcnn_labels.items():\n",
        "    with open(os.path.join(test_RCNN_labels_dir, file_name.replace(\".jpg\", \".json\")), \"w\") as f:\n",
        "        json.dump(label_data, f, indent=4)\n",
        "\n",
        "# Carpeta de val\n",
        "val_image_folder = \"/content/dataset_MaskRCNN/val/images\"\n",
        "val_mask_rcnn_labels = convert_to_mask_rcnn_labels(val_yolo_labels, val_image_folder)\n",
        "val_RCNN_labels_dir = \"/content/dataset_MaskRCNN/val/RCNN_labels\"\n",
        "\n",
        "# Guardar los resultados en la carpeta correspondiente\n",
        "if not os.path.exists(val_RCNN_labels_dir):\n",
        "    os.makedirs(val_RCNN_labels_dir)\n",
        "\n",
        "for file_name, label_data in val_mask_rcnn_labels.items():\n",
        "    with open(os.path.join(val_RCNN_labels_dir, file_name.replace(\".jpg\", \".json\")), \"w\") as f:\n",
        "        json.dump(label_data, f, indent=4)"
      ],
      "metadata": {
        "id": "VKhn1XL2ew85"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Juntamos todas las etiquetas en un solo .json para cada carpeta de Train, Test y Val."
      ],
      "metadata": {
        "id": "Mf8xY0yRvO3z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Rutas de los directorios de train, test y val\n",
        "train_RCNN_labels_dir = \"/content/dataset_MaskRCNN/train/RCNN_labels\"\n",
        "test_RCNN_labels_dir = \"/content/dataset_MaskRCNN/test/RCNN_labels\"\n",
        "val_RCNN_labels_dir = \"/content/dataset_MaskRCNN/val/RCNN_labels\"\n",
        "\n",
        "# Rutas de los directorios de salida fusionados\n",
        "merged_train_RCNN_labels_dir = \"/content/dataset_MaskRCNN/train/RCNN_labels_merged/\"\n",
        "merged_test_RCNN_labels_dir = \"/content/dataset_MaskRCNN/test/RCNN_labels_merged/\"\n",
        "merged_val_RCNN_labels_dir = \"/content/dataset_MaskRCNN/val/RCNN_labels_merged/\"\n",
        "\n",
        "# Crear los directorios de salida si no existen\n",
        "create_directories_if_not_exist(merged_train_RCNN_labels_dir, merged_test_RCNN_labels_dir, merged_val_RCNN_labels_dir)\n",
        "\n",
        "# Llamar a la función para fusionar los archivos JSON\n",
        "merge_mask_rcnn_labels(train_RCNN_labels_dir, merged_train_RCNN_labels_dir)\n",
        "merge_mask_rcnn_labels(test_RCNN_labels_dir, merged_test_RCNN_labels_dir)\n",
        "merge_mask_rcnn_labels(val_RCNN_labels_dir, merged_val_RCNN_labels_dir)"
      ],
      "metadata": {
        "id": "B86yZOh6MYJs"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Guardamos el nuevo dataset con ambas etiquetas.\n"
      ],
      "metadata": {
        "id": "UtbetlV4f8_3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Directorio de origen\n",
        "src_dir = \"/content/dataset_MaskRCNN\"\n",
        "\n",
        "# Directorio de destino\n",
        "dest_dir = \"/content/drive/MyDrive/TFM/dataset_MaskRCNN\"\n",
        "\n",
        "def copy_directory(src, dest):\n",
        "    if not os.path.exists(dest):\n",
        "        os.makedirs(dest)\n",
        "\n",
        "    for root, dirs, files in os.walk(src):\n",
        "        for name in dirs:\n",
        "            src_dir = os.path.join(root, name)\n",
        "            dest_dir = os.path.join(dest, os.path.relpath(src_dir, src))\n",
        "            if not os.path.exists(dest_dir):\n",
        "                os.makedirs(dest_dir)\n",
        "\n",
        "        for name in files:\n",
        "            src_file = os.path.join(root, name)\n",
        "            dest_file = os.path.join(dest, os.path.relpath(src_file, src))\n",
        "            if not os.path.exists(os.path.dirname(dest_file)):\n",
        "                os.makedirs(os.path.dirname(dest_file))\n",
        "            shutil.copy2(src_file, dest_file)\n",
        "\n",
        "# Copiar el directorio de origen al directorio de destino\n",
        "copy_directory(src_dir, dest_dir)\n",
        "\n",
        "print(f\"Directorio copiado de {src_dir} a {dest_dir}\")"
      ],
      "metadata": {
        "id": "H9PimM_9f8gi",
        "outputId": "196af875-5d44-4e72-d028-8af448f684b2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Directorio copiado de /content/dataset_MaskRCNN a /content/drive/MyDrive/TFM/dataset_MaskRCNN\n"
          ]
        }
      ]
    }
  ]
}