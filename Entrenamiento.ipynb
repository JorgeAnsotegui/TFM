{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMWO/4fnIMuERoq7ZwLpAaI",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/JorgeAnsotegui/TFM/blob/main/Entrenamiento.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        " # Importar librerías\n",
        "import os\n",
        "import sys\n",
        "import json\n",
        "import datetime\n",
        "import numpy as np\n",
        "import skimage.draw\n",
        "from google.colab import drive\n",
        "import itertools\n",
        "import math\n",
        "import logging\n",
        "import re\n",
        "import random\n",
        "from collections import OrderedDict\n",
        "import matplotlib\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.patches as patches\n",
        "import matplotlib.lines as lines\n",
        "from matplotlib.patches import Polygon"
      ],
      "metadata": {
        "id": "Adc-EBvNWy3R"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Montar Google Drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rN1ifqFEW2Ul",
        "outputId": "57182a98-ef17-49e5-9756-b4bf8d0e3b89"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Clonar el repositorio de GitHub\n",
        "!git clone https://github.com/mrk1992/mask-rcnn-tf2-us\n",
        "\n",
        "# Navegar al directorio del repositorio\n",
        "%cd Mask-R-CNN-using-Tensorflow2"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "D_TszgCloe60",
        "outputId": "bb109e26-5e9f-43be-a7d7-b7226777e219"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'mask-rcnn-tf2-us'...\n",
            "remote: Enumerating objects: 126, done.\u001b[K\n",
            "remote: Counting objects: 100% (9/9), done.\u001b[K\n",
            "remote: Compressing objects: 100% (3/3), done.\u001b[K\n",
            "remote: Total 126 (delta 7), reused 6 (delta 6), pack-reused 117\u001b[K\n",
            "Receiving objects: 100% (126/126), 73.92 MiB | 15.05 MiB/s, done.\n",
            "Resolving deltas: 100% (17/17), done.\n",
            "Updating files: 100% (93/93), done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Instalar las dependencias requeridas\n",
        "!pip install -r requirements.txt"
      ],
      "metadata": {
        "id": "alL_4IwZppl8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Numpy con bool da problemas.\n",
        "np.bool = np.bool_\n",
        "\n",
        "# Importar Mask RCNN\n",
        "sys.path.append(os.path.abspath('./'))  # Para encontrar la versión local de la librería\n",
        "from mrcnn.config import Config\n",
        "from mrcnn import model as modellib, utils\n",
        "\n",
        "# Ruta a los pesos pre-entrenados de COCO\n",
        "COCO_WEIGHTS_PATH = \"/content/drive/MyDrive/TFM/mask_rcnn_coco.h5\"\n",
        "\n",
        "# Directorio para guardar logs y checkpoints del modelo\n",
        "DEFAULT_LOGS_DIR = \"/content/drive/MyDrive/TFM/logs\""
      ],
      "metadata": {
        "id": "nT51NZzHXCiQ"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "############################################################\n",
        "#  Configuraciones\n",
        "############################################################\n",
        "\n",
        "class PolipoConfig(Config):\n",
        "    \"\"\"Configuración para entrenar con el dataset personalizado de pólipos.\"\"\"\n",
        "    NAME = \"polipo\"\n",
        "    IMAGES_PER_GPU = 2\n",
        "    NUM_CLASSES = 1 + 1  # Fondo + pólipo\n",
        "    STEPS_PER_EPOCH = 100\n",
        "    DETECTION_MIN_CONFIDENCE = 0.9"
      ],
      "metadata": {
        "id": "hLI12WFFXE-B"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "############################################################\n",
        "#  Dataset\n",
        "############################################################\n",
        "\n",
        "class PolipoDataset(utils.Dataset):\n",
        "    def load_polipo(self, dataset_dir, subset):\n",
        "        \"\"\"Cargar un subconjunto del dataset de pólipos.\"\"\"\n",
        "        self.add_class(\"polipo\", 1, \"polipo\")\n",
        "        assert subset in [\"train\", \"val\"]\n",
        "        dataset_dir = os.path.join(dataset_dir, subset)\n",
        "\n",
        "        annotations = json.load(open(os.path.join(dataset_dir, \"via_region_data.json\")))\n",
        "        annotations = list(annotations.values())\n",
        "        annotations = [a for a in annotations if a['regions']]\n",
        "\n",
        "        for a in annotations:\n",
        "            if type(a['regions']) is dict:\n",
        "                polygons = [r['shape_attributes'] for r in a['regions'].values()]\n",
        "            else:\n",
        "                polygons = [r['shape_attributes'] for r in a['regions']]\n",
        "\n",
        "            image_path = os.path.join(dataset_dir, a['filename'])\n",
        "            image = skimage.io.imread(image_path)\n",
        "            height, width = image.shape[:2]\n",
        "\n",
        "            self.add_image(\n",
        "                \"polipo\",\n",
        "                image_id=a['filename'],\n",
        "                path=image_path,\n",
        "                width=width, height=height,\n",
        "                polygons=polygons)\n",
        "\n",
        "    def load_mask(self, image_id):\n",
        "        image_info = self.image_info[image_id]\n",
        "        if image_info[\"source\"] != \"polipo\":\n",
        "            return super(self.__class__, self).load_mask(image_id)\n",
        "\n",
        "        info = self.image_info[image_id]\n",
        "        mask = np.zeros([info[\"height\"], info[\"width\"], len(info[\"polygons\"])],\n",
        "                        dtype=np.uint8)\n",
        "        for i, p in enumerate(info[\"polygons\"]):\n",
        "            rr, cc = skimage.draw.polygon(p['all_points_y'], p['all_points_x'])\n",
        "            mask[rr, cc, i] = 1\n",
        "\n",
        "        return mask.astype(np.bool), np.ones([mask.shape[-1]], dtype=np.int32)\n",
        "\n",
        "    def image_reference(self, image_id):\n",
        "        info = self.image_info[image_id]\n",
        "        if info[\"source\"] == \"polipo\":\n",
        "            return info[\"path\"]\n",
        "        else:\n",
        "            super(self.__class__, self).image_reference(image_id)\n"
      ],
      "metadata": {
        "id": "henDFm0ZXHnH"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Copiamos el dataset como nos nteresa en el directorio raiz."
      ],
      "metadata": {
        "id": "hpSBuYsUp2Yh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import shutil\n",
        "\n",
        "def create_directory_structure(base_dir):\n",
        "    subdirs = ['train', 'val', 'test']\n",
        "    for subdir in subdirs:\n",
        "        for category in ['images', 'labels']:\n",
        "            os.makedirs(os.path.join(base_dir, subdir, category), exist_ok=True)\n",
        "\n",
        "def copy_files(image_source_dir, label_source_dir, dest_dir):\n",
        "    # Copiar imágenes\n",
        "    image_files = [f for f in os.listdir(image_source_dir) if f.endswith(('.png', '.jpg', '.jpeg'))]\n",
        "    for image_file in image_files:\n",
        "        shutil.copy(os.path.join(image_source_dir, image_file), os.path.join(dest_dir, 'images', image_file))\n",
        "\n",
        "    # Copiar etiquetas\n",
        "    label_files = [f for f in os.listdir(label_source_dir) if f.endswith(('.json', '.xml', '.txt'))]\n",
        "    for label_file in label_files:\n",
        "        shutil.copy(os.path.join(label_source_dir, label_file), os.path.join(dest_dir, 'labels', label_file))\n",
        "\n",
        "# Directorios de origen\n",
        "source_base_dir = '/content/drive/MyDrive/TFM/dataset_MaskRCNN'\n",
        "image_source_dirs = {\n",
        "    'train': os.path.join(source_base_dir, 'train/images'),\n",
        "    'val': os.path.join(source_base_dir, 'val/images'),\n",
        "    'test': os.path.join(source_base_dir, 'test/images')\n",
        "}\n",
        "label_source_dirs = {\n",
        "    'train': os.path.join(source_base_dir, 'train/RCNN_labels_merged'),\n",
        "    'val': os.path.join(source_base_dir, 'val/RCNN_labels_merged'),\n",
        "    'test': os.path.join(source_base_dir, 'test/RCNN_labels_merged')\n",
        "}\n",
        "\n",
        "# Directorio de destino\n",
        "dest_base_dir = '/content/CurrentDataset'\n",
        "\n",
        "# Crear estructura de directorios\n",
        "create_directory_structure(dest_base_dir)\n",
        "\n",
        "# Copiar archivos a las nuevas ubicaciones\n",
        "for subset in ['train', 'val', 'test']:\n",
        "    copy_files(image_source_dirs[subset], label_source_dirs[subset], os.path.join(dest_base_dir, subset))\n",
        "\n",
        "print(\"Archivos copiados exitosamente.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "66U_F1rfg39o",
        "outputId": "3ae125e5-b1ed-4589-ef98-06914bb8c32e"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Archivos copiados exitosamente.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "############################################################\n",
        "#  Entrenamiento\n",
        "############################################################\n",
        "\n",
        "def train(model):\n",
        "    \"\"\"Entrenar el modelo.\"\"\"\n",
        "    dataset_train = PolipoDataset()\n",
        "    dataset_train.load_polyp(\"/content/CurrentDataset\", \"train\")\n",
        "    dataset_train.prepare()\n",
        "\n",
        "    dataset_val = PolipoDataset()\n",
        "    dataset_val.load_polyp(\"/content/CurrentDataset\", \"val\")\n",
        "    dataset_val.prepare()\n",
        "\n",
        "    print(\"Entrenando las cabezas de la red\")\n",
        "    model.train(dataset_train, dataset_val,\n",
        "                learning_rate=config.LEARNING_RATE,\n",
        "                epochs=30,\n",
        "                layers='heads')"
      ],
      "metadata": {
        "id": "9zT8hzZwXJJN"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "class AnchorsLayer(tf.keras.layers.Layer):\n",
        "    def __init__(self, num_anchors, **kwargs):\n",
        "        super(AnchorsLayer, self).__init__(**kwargs)\n",
        "        self.num_anchors = num_anchors\n",
        "\n",
        "    def build(self, input_shape):\n",
        "        # Implementación para construir las variables necesarias\n",
        "        self.anchors = self.add_weight(name='anchors',\n",
        "                                       shape=(2, self.num_anchors, 4),\n",
        "                                       initializer='uniform',\n",
        "                                       trainable=True)\n",
        "        super(AnchorsLayer, self).build(input_shape)\n",
        "\n",
        "    def call(self, inputs, **kwargs):\n",
        "        # Implementación para usar las variables creadas\n",
        "        return self.anchors\n",
        "\n",
        "# Ejemplo de uso en tu modelo MaskRCNN\n",
        "anchors = AnchorsLayer(num_anchors=261888)(inputs)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 176
        },
        "id": "S3GrXKs5mJ8y",
        "outputId": "e78ad43f-655e-4e73-ffa7-998c62f105f2"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'inputs' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-29-5db27d303be8>\u001b[0m in \u001b[0;36m<cell line: 21>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;31m# Ejemplo de uso en tu modelo MaskRCNN\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 21\u001b[0;31m \u001b[0manchors\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mAnchorsLayer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum_anchors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m261888\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'inputs' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "collapsed": true,
        "id": "-iLw71TWRbUo",
        "outputId": "8a5a7a79-a24e-4c8a-a754-2016722f0672"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Pesos:  /path/to/weights.h5\n",
            "Dataset:  /path/to/polyp/dataset/\n",
            "Logs:  /path/to/logs/\n",
            "\n",
            "Configurations:\n",
            "BACKBONE                       resnet101\n",
            "BACKBONE_STRIDES               [4, 8, 16, 32, 64]\n",
            "BATCH_SIZE                     2\n",
            "BBOX_STD_DEV                   [0.1 0.1 0.2 0.2]\n",
            "COMPUTE_BACKBONE_SHAPE         None\n",
            "DETECTION_MAX_INSTANCES        100\n",
            "DETECTION_MIN_CONFIDENCE       0.9\n",
            "DETECTION_NMS_THRESHOLD        0.3\n",
            "FPN_CLASSIF_FC_LAYERS_SIZE     1024\n",
            "GPU_COUNT                      1\n",
            "GRADIENT_CLIP_NORM             5.0\n",
            "IMAGES_PER_GPU                 2\n",
            "IMAGE_CHANNEL_COUNT            3\n",
            "IMAGE_MAX_DIM                  1024\n",
            "IMAGE_META_SIZE                14\n",
            "IMAGE_MIN_DIM                  800\n",
            "IMAGE_MIN_SCALE                0\n",
            "IMAGE_RESIZE_MODE              square\n",
            "IMAGE_SHAPE                    [1024 1024    3]\n",
            "LEARNING_MOMENTUM              0.9\n",
            "LEARNING_RATE                  0.001\n",
            "LOSS_WEIGHTS                   {'rpn_class_loss': 1.0, 'rpn_bbox_loss': 1.0, 'mrcnn_class_loss': 1.0, 'mrcnn_bbox_loss': 1.0, 'mrcnn_mask_loss': 1.0}\n",
            "MASK_POOL_SIZE                 14\n",
            "MASK_SHAPE                     [28, 28]\n",
            "MAX_GT_INSTANCES               100\n",
            "MEAN_PIXEL                     [123.7 116.8 103.9]\n",
            "MINI_MASK_SHAPE                (56, 56)\n",
            "NAME                           polipo\n",
            "NUM_CLASSES                    2\n",
            "POOL_SIZE                      7\n",
            "POST_NMS_ROIS_INFERENCE        1000\n",
            "POST_NMS_ROIS_TRAINING         2000\n",
            "PRE_NMS_LIMIT                  6000\n",
            "ROI_POSITIVE_RATIO             0.33\n",
            "RPN_ANCHOR_RATIOS              [0.5, 1, 2]\n",
            "RPN_ANCHOR_SCALES              (32, 64, 128, 256, 512)\n",
            "RPN_ANCHOR_STRIDE              1\n",
            "RPN_BBOX_STD_DEV               [0.1 0.1 0.2 0.2]\n",
            "RPN_NMS_THRESHOLD              0.7\n",
            "RPN_TRAIN_ANCHORS_PER_IMAGE    256\n",
            "STEPS_PER_EPOCH                100\n",
            "TOP_DOWN_PYRAMID_SIZE          256\n",
            "TRAIN_BN                       False\n",
            "TRAIN_ROIS_PER_IMAGE           200\n",
            "USE_MINI_MASK                  True\n",
            "USE_RPN_ROIS                   True\n",
            "VALIDATION_STEPS               50\n",
            "WEIGHT_DECAY                   0.0001\n",
            "\n",
            "\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "Exception encountered when calling layer \"anchors\" (type Lambda).\n\n\nThe following Variables were created within a Lambda layer (anchors)\nbut are not tracked by said layer:\n  <tf.Variable 'anchors/Variable:0' shape=(2, 261888, 4) dtype=float32>\nThe layer cannot safely ensure proper Variable reuse across multiple\ncalls, and consequently this behavior is disallowed for safety. Lambda\nlayers are not well suited to stateful computation; instead, writing a\nsubclassed Layer is the recommend way to define layers with\nVariables.\n\nCall arguments received by layer \"anchors\" (type Lambda):\n  • inputs=tf.Tensor(shape=(None, None, None, 3), dtype=float32)\n  • mask=None\n  • training=None",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-28-0d1a8ece1e21>\u001b[0m in \u001b[0;36m<cell line: 65>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     64\u001b[0m \u001b[0;31m# Crear el modelo\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcommand\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"train\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 66\u001b[0;31m     model = modellib.MaskRCNN(mode=\"training\", config=config,\n\u001b[0m\u001b[1;32m     67\u001b[0m                               model_dir=args.logs)\n\u001b[1;32m     68\u001b[0m \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/mask-rcnn-tf2-us/mrcnn/model.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, mode, config, model_dir)\u001b[0m\n\u001b[1;32m   1864\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel_dir\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel_dir\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1865\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_log_dir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1866\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuild\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1867\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1868\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mbuild\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/mask-rcnn-tf2-us/mrcnn/model.py\u001b[0m in \u001b[0;36mbuild\u001b[0;34m(self, mode, config)\u001b[0m\n\u001b[1;32m   1964\u001b[0m             \u001b[0manchors\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbroadcast_to\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0manchors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mBATCH_SIZE\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0manchors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1965\u001b[0m             \u001b[0;31m# A hack to get around Keras's bad support for constants\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1966\u001b[0;31m             \u001b[0manchors\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mKL\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mLambda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mVariable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0manchors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"anchors\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_image\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1967\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1968\u001b[0m             \u001b[0manchors\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput_anchors\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     68\u001b[0m             \u001b[0;31m# To get the full stack trace, call:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m             \u001b[0;31m# `tf.debugging.disable_traceback_filtering()`\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 70\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     71\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     72\u001b[0m             \u001b[0;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/layers/core/lambda_layer.py\u001b[0m in \u001b[0;36m_check_variables\u001b[0;34m(self, created_variables, accessed_variables)\u001b[0m\n\u001b[1;32m    245\u001b[0m           Variables.\"\"\"\n\u001b[1;32m    246\u001b[0m             ).format(name=self.name, variable_str=variable_str)\n\u001b[0;32m--> 247\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merror_str\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    248\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    249\u001b[0m         untracked_used_vars = [\n",
            "\u001b[0;31mValueError\u001b[0m: Exception encountered when calling layer \"anchors\" (type Lambda).\n\n\nThe following Variables were created within a Lambda layer (anchors)\nbut are not tracked by said layer:\n  <tf.Variable 'anchors/Variable:0' shape=(2, 261888, 4) dtype=float32>\nThe layer cannot safely ensure proper Variable reuse across multiple\ncalls, and consequently this behavior is disallowed for safety. Lambda\nlayers are not well suited to stateful computation; instead, writing a\nsubclassed Layer is the recommend way to define layers with\nVariables.\n\nCall arguments received by layer \"anchors\" (type Lambda):\n  • inputs=tf.Tensor(shape=(None, None, None, 3), dtype=float32)\n  • mask=None\n  • training=None"
          ]
        }
      ],
      "source": [
        "# Importar los módulos necesarios\n",
        "import os\n",
        "import argparse\n",
        "\n",
        "# Definir las variables simuladas (sustituir con los valores deseados)\n",
        "args_command = \"train\"  # Opciones: \"train\" o \"splash\"\n",
        "args_dataset = \"/path/to/polyp/dataset/\"  # Ruta al dataset de pólipos\n",
        "args_weights = \"/path/to/weights.h5\"  # Ruta a los pesos .h5 o 'coco'\n",
        "args_logs = \"/path/to/logs/\"  # Directorio de logs y checkpoints\n",
        "args_image = \"path or URL to image\"  # Ruta o URL de la imagen\n",
        "args_video = \"path or URL to video\"  # Ruta o URL del video\n",
        "\n",
        "# Configuración de los argumentos simulados\n",
        "parser = argparse.ArgumentParser(\n",
        "    description='Entrenar Mask R-CNN para detectar pólipos.')\n",
        "parser.add_argument(\"command\",\n",
        "                    metavar=\"<command>\",\n",
        "                    help=\"'train' o 'splash'\")\n",
        "parser.add_argument('--dataset', required=False,\n",
        "                    metavar=\"/path/to/polyp/dataset/\",\n",
        "                    help='Directorio del dataset de pólipos')\n",
        "parser.add_argument('--weights', required=True,\n",
        "                    metavar=\"/path/to/weights.h5\",\n",
        "                    help=\"Ruta a los pesos .h5 o 'coco'\")\n",
        "parser.add_argument('--logs', required=False,\n",
        "                    default=DEFAULT_LOGS_DIR,\n",
        "                    metavar=\"/path/to/logs/\",\n",
        "                    help='Directorio de logs y checkpoints (default=logs/)')\n",
        "parser.add_argument('--image', required=False,\n",
        "                    metavar=\"path or URL to image\",\n",
        "                    help='Imagen para aplicar el efecto color splash')\n",
        "parser.add_argument('--video', required=False,\n",
        "                    metavar=\"path or URL to video\",\n",
        "                    help='Video para aplicar el efecto color splash')\n",
        "args = parser.parse_args([\n",
        "    args_command,\n",
        "    '--dataset', args_dataset,\n",
        "    '--weights', args_weights,\n",
        "    '--logs', args_logs,\n",
        "    '--image', args_image,\n",
        "    '--video', args_video\n",
        "])\n",
        "\n",
        "# Validar argumentos\n",
        "if args.command == \"train\":\n",
        "    assert args.dataset, \"El argumento --dataset es requerido para entrenar\"\n",
        "elif args.command == \"splash\":\n",
        "    assert args.image or args.video, \"Proveer --image o --video para aplicar color splash\"\n",
        "\n",
        "print(\"Pesos: \", args.weights)\n",
        "print(\"Dataset: \", args.dataset)\n",
        "print(\"Logs: \", args.logs)\n",
        "\n",
        "# Configuraciones (suponemos que PolypConfig y modellib ya están definidos en otro lugar)\n",
        "if args.command == \"train\":\n",
        "    config = PolipoConfig()\n",
        "else:\n",
        "    class InferenceConfig(PolipoConfig):\n",
        "        GPU_COUNT = 1\n",
        "        IMAGES_PER_GPU = 1\n",
        "    config = InferenceConfig()\n",
        "config.display()\n",
        "\n",
        "# Crear el modelo\n",
        "if args.command == \"train\":\n",
        "    model = modellib.MaskRCNN(mode=\"training\", config=config,\n",
        "                              model_dir=args.logs)\n",
        "else:\n",
        "    model = modellib.MaskRCNN(mode=\"inference\", config=config,\n",
        "                              model_dir=args.logs)\n",
        "\n",
        "# Seleccionar el archivo de pesos a cargar\n",
        "if args.weights.lower() == \"coco\":\n",
        "    weights_path = COCO_WEIGHTS_PATH\n",
        "    if not os.path.exists(weights_path):\n",
        "        utils.download_trained_weights(weights_path)\n",
        "elif args.weights.lower() == \"last\":\n",
        "    weights_path = model.find_last()\n",
        "elif args.weights.lower() == \"imagenet\":\n",
        "    weights_path = model.get_imagenet_weights()\n",
        "else:\n",
        "    weights_path = args.weights\n",
        "\n",
        "# Cargar los pesos\n",
        "print(\"Cargando pesos \", weights_path)\n",
        "if args.weights.lower() == \"coco\":\n",
        "    model.load_weights(weights_path, by_name=True, exclude=[\n",
        "        \"mrcnn_class_logits\", \"mrcnn_bbox_fc\",\n",
        "        \"mrcnn_bbox\", \"mrcnn_mask\"])\n",
        "else:\n",
        "    model.load_weights(weights_path, by_name=True)\n",
        "\n",
        "# Entrenar o evaluar\n",
        "if args.command == \"train\":\n",
        "    train(model)\n",
        "elif args.command == \"splash\":\n",
        "    detect_and_color_splash(model, image_path=args.image,\n",
        "                            video_path=args.video)\n",
        "else:\n",
        "    print(\"'{}' no es reconocido. Use 'train' o 'splash'\".format(args.command))\n",
        "\n"
      ]
    }
  ]
}