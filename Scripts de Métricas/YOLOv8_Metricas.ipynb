{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "34687c45-2495-400c-bda3-d54bc33a7f1c",
   "metadata": {},
   "source": [
    "# Obtención de los Hyperparametros Optimizados para modelo de detección de YoloV8"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6973144-c7f6-4030-8172-d4679f31cfa4",
   "metadata": {},
   "source": [
    "**Importamos las librerias y modulos necesarios:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "599070d4-6df3-496a-b260-e6b2231943e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ultralytics import YOLO\n",
    "from matplotlib import pyplot as plt\n",
    "from PIL import Image\n",
    "import optuna\n",
    "import locale\n",
    "import os\n",
    "import json\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import yaml\n",
    "import torch\n",
    "import cv2\n",
    "import random\n",
    "from pathlib import Path\n",
    "import time\n",
    "import shutil\n",
    "from matplotlib import pyplot as plt\n",
    "import re"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de1f0cfc-a55b-47f6-8425-3e08bd014a1b",
   "metadata": {},
   "source": [
    "Asegurar que hay una gpu disponible"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b84ac6ec-5e8e-4586-8123-6265c179259e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDA disponible: True\n",
      "Número de dispositivos CUDA disponibles: 1\n",
      "Nombre del dispositivo CUDA actual: NVIDIA GeForce RTX 3090 Ti\n"
     ]
    }
   ],
   "source": [
    "print(\"CUDA disponible:\", torch.cuda.is_available())\n",
    "if torch.cuda.is_available():\n",
    "    print(\"Número de dispositivos CUDA disponibles:\", torch.cuda.device_count())\n",
    "    print(\"Nombre del dispositivo CUDA actual:\", torch.cuda.get_device_name())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b479a1b-9ff4-457b-aefa-d466e3531cd5",
   "metadata": {},
   "source": [
    "**Rutas del directorio donde se han guarrdad los modelos**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "3928893b-6816-4c3d-af23-212ef7693a82",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ruta al directorio que contiene todos los trials\n",
    "ruta_resultados = \"models/Final/YoloV8_n_25_fix/\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fd40f59",
   "metadata": {},
   "source": [
    "**Juntamos todas las metricas en un solo archivo**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "1b27fb1f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Métricas de todos los trials guardadas en models/Final/YoloV8_n_25_fix/all_metrics.json\n"
     ]
    }
   ],
   "source": [
    "# Contar el número de carpetas que siguen el patrón \"trial_\"\n",
    "trial_folders = [folder for folder in os.listdir(ruta_resultados) if folder.startswith(\"trial_\") and folder.split(\"_\")[1].isdigit()]\n",
    "n_trials = len(trial_folders)\n",
    "print(n_trials)\n",
    "\n",
    "# Crear una lista para almacenar todas las métricas\n",
    "all_metrics = []\n",
    "\n",
    "# Recorrer todas las carpetas de trials y leer los archivos JSON de métricas\n",
    "for trial_num in range(n_trials):\n",
    "    trial_dir = os.path.join(ruta_resultados, f\"trial_{trial_num}\")\n",
    "    result_path = os.path.join(trial_dir, f\"trial_{trial_num}_result.json\")\n",
    "    # result_path = os.path.join(trial_dir, f\"metrics.json\")\n",
    "    if os.path.exists(result_path):\n",
    "        with open(result_path, 'r') as f:\n",
    "            trial_metrics = json.load(f)\n",
    "            trial_metrics[\"trial_number\"] = trial_num  # Añadir el número del trial a las métricas\n",
    "            all_metrics.append(trial_metrics)\n",
    "\n",
    "# Guardar todas las métricas en un archivo JSON\n",
    "all_metrics_path = os.path.join(ruta_resultados, \"all_metrics.json\")\n",
    "with open(all_metrics_path, 'w') as f:\n",
    "    json.dump(all_metrics, f, indent=2)\n",
    "\n",
    "print(f\"Métricas de todos los trials guardadas en {all_metrics_path}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4ca169c",
   "metadata": {},
   "source": [
    "**Se verifica con que dataset fue entrenado el modelo**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "03d3497f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "El archivo YAML utilizado es: /home/hpc22/computer_vision_colon/TFM/Entrenamiento/datasets/Polipos265_Detectron2FIX_YoloV8/data.yaml\n"
     ]
    }
   ],
   "source": [
    "# Leer el archivo all_metrics.json\n",
    "with open(all_metrics_path, 'r') as f:\n",
    "    all_metrics = json.load(f)\n",
    "\n",
    "# Extraer el valor del campo \"Dataset\"\n",
    "if all_metrics:\n",
    "    data_yaml_path = all_metrics[0][\"Dataset\"]\n",
    "else:\n",
    "    data_yaml_path = None\n",
    "\n",
    "print(f\"El archivo YAML utilizado es: {data_yaml_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "a6b2ef4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def crear_directorio(directorio):\n",
    "    \"\"\"Crea un directorio si no existe.\"\"\"\n",
    "    print(directorio)\n",
    "    if not os.path.exists(directorio):\n",
    "        os.makedirs(directorio)\n",
    "        print(f\"Directorio '{directorio}' creado.\")\n",
    "    else:\n",
    "        print(f\"El directorio '{directorio}' ya existe.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "fdebc75b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def procesar_trial(trial_path):\n",
    "    # Definir la ruta para la carpeta del trial y el archivo all_metrics.json\n",
    "    model_path = os.path.join(trial_path, \"weights/best.pt\")\n",
    "    \n",
    "    # Cragamos el modelo     \n",
    "    model_segmentation = YOLO(model_path)\n",
    "    print(\"\\n\\nCargado modelo: \", model_path)\n",
    "    \n",
    "    # Crear carpeta para coordenadas\n",
    "    output_folder = os.path.join(trial_path, \"coordenadas_test\")\n",
    "    crear_directorio(output_folder)\n",
    "    \n",
    "    with open(data_yaml_path, 'r') as f:\n",
    "        data_yaml = yaml.safe_load(f)\n",
    "\n",
    "    # Obtener la ruta relativa del directorio de test\n",
    "    relative_test_folder = data_yaml['test']\n",
    "    \n",
    "    # Imprimir la ruta de validación para verificar\n",
    "    print(f\"Ruta de la carpeta de test relativa: {relative_test_folder}\")\n",
    "\n",
    "    clean_test_folder = relative_test_folder.replace(\"../\", \"\", 1)\n",
    "    print(f\"Ruta de la carpeta de test limpia: {clean_test_folder}\")\n",
    "\n",
    "    # Obtener el directorio base del archivo YAML\n",
    "    yaml_base_path = Path(data_yaml_path).parent\n",
    "\n",
    "    # Imprimir la ruta de validación para verificar\n",
    "    print(f\"Ruta de la carpeta YAML parent: {yaml_base_path}\")\n",
    "\n",
    "    # Resolver el camino relativo correctamente a partir de la ruta base\n",
    "    test_folder = os.path.join(yaml_base_path, clean_test_folder)\n",
    "\n",
    "    # Imprimir la ruta de validación para verificar\n",
    "    print(f\"Ruta de la carpeta de test: {test_folder}\")\n",
    "\n",
    "    # Procesar imágenes\n",
    "    for img_path in Path(test_folder).glob('*'):\n",
    "        print(f\"Procesando imagen: {img_path}\")\n",
    "\n",
    "        # Realizar predicción\n",
    "        results = model_segmentation(img_path)\n",
    "\n",
    "        # Asegurarse de que results sea una lista\n",
    "        if isinstance(results, list):\n",
    "            # Usar el primer elemento de la lista como objeto Results\n",
    "            result = results[0]\n",
    "        else:\n",
    "            result = results\n",
    "\n",
    "        # Verificar el tipo y formato del objeto result\n",
    "#         print(f\"Tipo de resultados: {type(result)}\")\n",
    "#         print(f\"Contenido de resultados: {result}\")\n",
    "\n",
    "        # Si result es una instancia de Results\n",
    "        if hasattr(result, 'save_txt'):\n",
    "            # Guardar directamente las coordenadas en un archivo .txt\n",
    "            txt_path = os.path.join(output_folder, f\"{img_path.stem}.txt\")\n",
    "            result.save_txt(txt_path, save_conf=True)  # Guarda con confianza si es necesario\n",
    "\n",
    "            # Esperar un breve momento para asegurarse de que el archivo se haya guardado\n",
    "            time.sleep(0.1)\n",
    "\n",
    "            # Verificar y corregir coordenadas impares en el archivo guardado\n",
    "            if os.path.exists(txt_path):\n",
    "                with open(txt_path, 'r') as f:\n",
    "                    lines = f.readlines()\n",
    "\n",
    "                corrected_lines = []\n",
    "                for line in lines:\n",
    "                    parts = line.strip().split()\n",
    "                    if len(parts) % 2 == 0:\n",
    "                        parts = parts[:-1]  # Eliminar el último elemento para hacer el número de coordenadas par\n",
    "                    corrected_lines.append(' '.join(parts))\n",
    "\n",
    "                # Guardar las líneas corregidas\n",
    "                with open(txt_path, 'w') as f:\n",
    "                    f.write('\\n'.join(corrected_lines))\n",
    "\n",
    "                print(f\"Opción 1. Archivo de coordenadas guardado y corregido en: {txt_path}\")\n",
    "            else:\n",
    "                print(f\"Error: No se pudo encontrar el archivo {txt_path} después de guardarlo.\")\n",
    "\n",
    "        else:\n",
    "            # Extraer resultados manualmente si no se puede usar save_txt\n",
    "            detections = result.xyxy[0].cpu().numpy()  # Usar el formato adecuado\n",
    "\n",
    "            # Contar el número de objetos detectados\n",
    "            num_objects = len(detections)\n",
    "            print(f\"Número de objetos detectados: {num_objects}\")\n",
    "\n",
    "            if num_objects > 0:\n",
    "                print(\"Se han detectado objetos en esta imagen:\")\n",
    "                for det in detections:\n",
    "                    class_id, x_min, y_min, x_max, y_max, confidence = det\n",
    "                    print(f\"Clase: {int(class_id)}, Confianza: {confidence}, Coordenadas: [{x_min}, {y_min}, {x_max}, {y_max}]\")\n",
    "            else:\n",
    "                print(\"No se detectaron objetos en esta imagen.\")\n",
    "\n",
    "            # Guardar coordenadas en archivo .txt\n",
    "            txt_path = os.path.join(output_folder, f\"{img_path.stem}.txt\")\n",
    "            with open(txt_path, 'w') as f:\n",
    "                for det in detections:\n",
    "                    class_id, x_min, y_min, x_max, y_max, confidence = det\n",
    "                    x_center = (x_min + x_max) / 2\n",
    "                    y_center = (y_min + y_max) / 2\n",
    "                    width = x_max - x_min\n",
    "                    height = y_max - y_min\n",
    "                    f.write(f\"{int(class_id)} {x_center} {y_center} {width} {height}\\n\")\n",
    "\n",
    "            # Verificar y corregir coordenadas impares en el archivo guardado\n",
    "            if os.path.exists(txt_path):\n",
    "                with open(txt_path, 'r') as f:\n",
    "                    lines = f.readlines()\n",
    "\n",
    "                corrected_lines = []\n",
    "                for line in lines:\n",
    "                    parts = line.strip().split()\n",
    "                    if len(parts) % 2 == 0:\n",
    "                        parts = parts[:-1]  # Eliminar el último elemento para hacer el número de coordenadas par\n",
    "                    corrected_lines.append(' '.join(parts))\n",
    "\n",
    "                # Guardar las líneas corregidas\n",
    "                with open(txt_path, 'w') as f:\n",
    "                    f.write('\\n'.join(corrected_lines))\n",
    "\n",
    "                print(f\"Opción 2. Archivo de coordenadas guardado y corregido en: {txt_path}\")\n",
    "            else:\n",
    "                print(f\"Error: No se pudo encontrar el archivo {txt_path} después de guardarlo.\")\n",
    "\n",
    "        print(\"-\" * 40)  # Separador para mayor claridad en la salida"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "94be3ca3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# def borrar_coordenadas_test(trial_path):\n",
    "#     \"\"\"Eliminar la carpeta coordenadas_test si existe dentro de trial_path.\"\"\"\n",
    "#     coordenadas_test_path = os.path.join(trial_path, \"coordenadas_test\")\n",
    "#     if os.path.exists(coordenadas_test_path) and os.path.isdir(coordenadas_test_path):\n",
    "#         shutil.rmtree(coordenadas_test_path)\n",
    "#         print(f\"Carpeta 'coordenadas_test' eliminada en: {trial_path}\")\n",
    "#     else:\n",
    "#         print(f\"No se encontró la carpeta 'coordenadas_test' en: {trial_path}\")\n",
    "        \n",
    "# # Iterar sobre cada carpeta trial y borrar coordenadas_test\n",
    "# for folder in os.listdir(ruta_resultados):\n",
    "#     trial_path = os.path.join(ruta_resultados, folder)\n",
    "#     if os.path.isdir(trial_path) and folder.startswith(\"trial_\") and folder.split(\"_\")[1].isdigit():\n",
    "#         borrar_coordenadas_test(trial_path)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "bf401f1a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Iterar sobre cada carpeta trial y procesar\n",
    "for folder in os.listdir(ruta_resultados):\n",
    "    trial_path = os.path.join(ruta_resultados, folder)\n",
    "    if os.path.isdir(trial_path) and folder.startswith(\"trial_\") and folder.split(\"_\")[1].isdigit():\n",
    "        procesar_trial(trial_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "6736ce07",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Función para leer las coordenadas de YOLO\n",
    "def read_yolo_mask(filename):\n",
    "    with open(filename, 'r') as file:\n",
    "        lines = file.readlines()\n",
    "    \n",
    "    masks = {}\n",
    "    \n",
    "    for line in lines:\n",
    "        data = list(map(float, line.strip().split()))\n",
    "        category = int(data[0])\n",
    "        coords = np.array(data[1:]).reshape(-1, 2)\n",
    "        \n",
    "        if category not in masks:\n",
    "            masks[category] = []\n",
    "        masks[category].append(coords)\n",
    "    \n",
    "    return masks\n",
    "\n",
    "# Convertir coordenadas normalizadas a píxeles\n",
    "def normalized_to_pixel_coords(coords, img_width, img_height):\n",
    "    coords[:, 0] *= img_width\n",
    "    coords[:, 1] *= img_height\n",
    "    return coords\n",
    "\n",
    "# Crear una máscara binaria para una categoría\n",
    "def create_binary_mask(coords_list, img_width, img_height):\n",
    "    mask = np.zeros((img_height, img_width), dtype=np.uint8)\n",
    "    \n",
    "    for coords in coords_list:\n",
    "        coords = normalized_to_pixel_coords(coords, img_width, img_height)\n",
    "        coords = coords.astype(np.int32)\n",
    "        cv2.fillPoly(mask, [coords], 1)\n",
    "    \n",
    "    return mask\n",
    "\n",
    "# Crear una imagen combinada con máscaras\n",
    "def create_combined_image(gt_file, pred_file, img_width, img_height):\n",
    "    # Leer las coordenadas\n",
    "    gt_masks = read_yolo_mask(gt_file)\n",
    "    pred_masks = read_yolo_mask(pred_file)\n",
    "\n",
    "    # Crear imágenes de fondo negro\n",
    "    combined_image = np.zeros((img_height, img_width, 3), dtype=np.uint8)\n",
    "\n",
    "    # Crear máscaras binarias para cada categoría\n",
    "    gt_binary_masks = {category: create_binary_mask(coords_list, img_width, img_height)\n",
    "                       for category, coords_list in gt_masks.items()}\n",
    "    pred_binary_masks = {category: create_binary_mask(coords_list, img_width, img_height)\n",
    "                         for category, coords_list in pred_masks.items()}\n",
    "\n",
    "    # Pintar las máscaras en la imagen combinada\n",
    "    for category in gt_binary_masks:\n",
    "        gt_mask = gt_binary_masks[category]\n",
    "        pred_mask = pred_binary_masks.get(category, np.zeros((img_height, img_width), dtype=np.uint8))\n",
    "\n",
    "        # Convertir las máscaras binarias a colores\n",
    "        gt_colored = np.stack([gt_mask * 255, np.zeros_like(gt_mask), np.zeros_like(gt_mask)], axis=-1)  # Azul\n",
    "        pred_colored = np.stack([np.zeros_like(pred_mask), np.zeros_like(pred_mask), pred_mask * 255], axis=-1)  # Rojo\n",
    "\n",
    "        # Superponer las máscaras en la imagen combinada con transparencia\n",
    "        combined_image = cv2.addWeighted(combined_image, 1, gt_colored, 0.5, 0)\n",
    "        combined_image = cv2.addWeighted(combined_image, 1, pred_colored, 0.5, 0)\n",
    "\n",
    "    return combined_image\n",
    "\n",
    "# Extraer el número del trial del nombre de la carpeta\n",
    "def extract_trial_number(trial_path):\n",
    "    match = re.search(r'trial_(\\d+)', os.path.basename(trial_path))\n",
    "    return int(match.group(1)) if match else None\n",
    "\n",
    "# Crear la carpeta Figuras si no existe y generar las imágenes combinadas y las imágenes visuales\n",
    "def crear_figuras(trial_path, gt_files, pred_files, ground_truths, predictions):\n",
    "    # Crear la carpeta de Figuras si no existe\n",
    "    figuras_folder = os.path.join(trial_path, 'Figuras')\n",
    "    if not os.path.exists(figuras_folder):\n",
    "        os.makedirs(figuras_folder)\n",
    "\n",
    "    # Seleccionar aleatoriamente 3 pares de archivos\n",
    "    pairs = random.sample(list(gt_files & pred_files), min(3, len(gt_files & pred_files)))\n",
    "\n",
    "    # Obtener la ruta de las imágenes originales\n",
    "    dataset_test_path = os.path.dirname(ground_truths)\n",
    "    dataset_test_images = os.path.join(dataset_test_path, 'images')\n",
    "\n",
    "    for file_name in pairs:\n",
    "        true_file = os.path.join(ground_truths, f\"{file_name}.txt\")\n",
    "        pred_file = os.path.join(predictions, f\"{file_name}.txt\")\n",
    "        image_file_path = os.path.join(dataset_test_images, f\"{file_name}.jpg\")  # Asumiendo que las imágenes son .jpg\n",
    "        \n",
    "        # Leer la imagen original\n",
    "        original_image = cv2.imread(image_file_path)\n",
    "        img_height, img_width = original_image.shape[:2]\n",
    "        \n",
    "        # Crear la imagen combinada de las máscaras\n",
    "        combined_image = create_combined_image(true_file, pred_file, img_width, img_height)\n",
    "\n",
    "        # Guardar la imagen combinada\n",
    "        combined_image_file = os.path.join(figuras_folder, f\"{file_name}_mask_eval.png\")\n",
    "        cv2.imwrite(combined_image_file, combined_image)\n",
    "\n",
    "        # Dibujar los contornos de las máscaras en la imagen original\n",
    "        gt_masks = read_yolo_mask(true_file)\n",
    "        pred_masks = read_yolo_mask(pred_file)\n",
    "\n",
    "        for category in gt_masks:\n",
    "            for coords in gt_masks[category]:\n",
    "                pixel_coords = normalized_to_pixel_coords(coords.copy(), img_width, img_height).astype(np.int32)\n",
    "                cv2.polylines(original_image, [pixel_coords], isClosed=True, color=(255, 0, 0), thickness=2)  # Azul para ground truth\n",
    "\n",
    "        for category in pred_masks:\n",
    "            for coords in pred_masks[category]:\n",
    "                pixel_coords = normalized_to_pixel_coords(coords.copy(), img_width, img_height).astype(np.int32)\n",
    "                cv2.polylines(original_image, [pixel_coords], isClosed=True, color=(0, 0, 255), thickness=2)  # Rojo para predicción\n",
    "\n",
    "        # Guardar la imagen visual\n",
    "        visual_image_file = os.path.join(figuras_folder, f\"{file_name}_mask_visual.png\")\n",
    "        cv2.imwrite(visual_image_file, original_image)\n",
    "\n",
    "# Definir la función para procesar cada trial\n",
    "def evaluar_trial(trial_path):\n",
    "    # Extraer el número del trial\n",
    "    trial_number = extract_trial_number(trial_path)\n",
    "    if trial_number is None:\n",
    "        raise ValueError(f\"No se pudo extraer el número del trial de la ruta: {trial_path}\")\n",
    "\n",
    "    # Definir las rutas dentro del trial\n",
    "    dataset_path = os.path.dirname(data_yaml_path)\n",
    "    dataset_test_labels = os.path.join(dataset_path, 'test/labels')\n",
    "    ground_truths = dataset_test_labels\n",
    "    output_folder = os.path.join(trial_path, \"coordenadas_test\")\n",
    "    predictions = output_folder\n",
    "\n",
    "    # Umbral para binarización\n",
    "    threshold = 0.5\n",
    "\n",
    "    # Lista para almacenar los resultados\n",
    "    results = []\n",
    "\n",
    "    # Obtener una lista de los archivos de etiquetas y predicciones\n",
    "    print(ground_truths)\n",
    "    gt_files = {os.path.splitext(f)[0] for f in os.listdir(ground_truths) if f.endswith('.txt')}\n",
    "    print(predictions)\n",
    "    pred_files = {os.path.splitext(f)[0] for f in os.listdir(predictions) if f.endswith('.txt')}\n",
    "\n",
    "    # Encontrar archivos comunes en ambas carpetas\n",
    "    common_files = gt_files.intersection(pred_files)\n",
    "\n",
    "    # Crear imágenes de las máscaras y de las visuales con contornos\n",
    "    crear_figuras(trial_path, gt_files, pred_files, ground_truths, predictions)\n",
    "\n",
    "    # Procesar cada archivo común\n",
    "    for file_name in common_files:\n",
    "        true_file = os.path.join(ground_truths, f\"{file_name}.txt\")\n",
    "        pred_file = os.path.join(predictions, f\"{file_name}.txt\")\n",
    "\n",
    "        # Leer y procesar las coordenadas de YOLO para ground truth\n",
    "        gt_masks = read_yolo_mask(true_file)\n",
    "        pred_masks = read_yolo_mask(pred_file)\n",
    "\n",
    "        # Asignar dimensiones de imagen (reemplazar con las dimensiones reales)\n",
    "        img_width, img_height = 640, 480\n",
    "\n",
    "        # Crear máscaras binarias para cada categoría\n",
    "        gt_binary_masks = {category: create_binary_mask(coords_list, img_width, img_height)\n",
    "                           for category, coords_list in gt_masks.items()}\n",
    "        pred_binary_masks = {category: create_binary_mask(coords_list, img_width, img_height)\n",
    "                             for category, coords_list in pred_masks.items()}\n",
    "\n",
    "        # Asegurarse de que las categorías estén presentes en ambas máscaras\n",
    "        all_categories = set(gt_binary_masks.keys()).union(pred_binary_masks.keys())\n",
    "        \n",
    "        for category in all_categories:\n",
    "            gt_mask = gt_binary_masks.get(category, np.zeros((img_height, img_width), dtype=np.uint8))\n",
    "            pred_mask = pred_binary_masks.get(category, np.zeros((img_height, img_width), dtype=np.uint8))\n",
    "            \n",
    "            # Binarizar las máscaras\n",
    "            binary_true_mask = (gt_mask > threshold).astype(int)\n",
    "            binary_predicted_mask = (pred_mask > threshold).astype(int)\n",
    "            \n",
    "            # Calcular TP, TN, FP, FN\n",
    "            TP = np.sum((binary_predicted_mask == 1) & (binary_true_mask == 1))\n",
    "            FP = np.sum((binary_predicted_mask == 1) & (binary_true_mask == 0))\n",
    "            TN = np.sum((binary_predicted_mask == 0) & (binary_true_mask == 0))\n",
    "            FN = np.sum((binary_predicted_mask == 0) & (binary_true_mask == 1))\n",
    "            \n",
    "            # Guardar los resultados\n",
    "            results.append([file_name, category, TP, TN, FP, FN])\n",
    "\n",
    "    # Crear un DataFrame para visualizar los resultados\n",
    "    results_df = pd.DataFrame(results, columns=['Filename', 'Category', 'TP', 'TN', 'FP', 'FN'])\n",
    "\n",
    "    # Eliminar la columna 'Filename' antes de calcular la media\n",
    "    df_for_mean = results_df.drop(columns=['Filename'])\n",
    "\n",
    "    # Calcular las medias por categoría\n",
    "    mean_results = df_for_mean.groupby('Category').mean()\n",
    "\n",
    "    # Calcular las medias globales\n",
    "    mean_TP = df_for_mean['TP'].mean()\n",
    "    mean_TN = df_for_mean['TN'].mean()\n",
    "    mean_FP = df_for_mean['FP'].mean()\n",
    "    mean_FN = df_for_mean['FN'].mean()\n",
    "\n",
    "    # Calcular las métricas\n",
    "    precision_avg = mean_TP / (mean_TP + mean_FP) if (mean_TP + mean_FP) > 0 else 0\n",
    "    recall_avg = mean_TP / (mean_TP + mean_FN) if (mean_TP + mean_FN) > 0 else 0\n",
    "    f1_score_avg = (2 * precision_avg * recall_avg) / (precision_avg + recall_avg) if (precision_avg + recall_avg) > 0 else 0\n",
    "    iou_avg = mean_TP / (mean_TP + mean_FP + mean_FN) if (mean_TP + mean_FP + mean_FN) > 0 else 0\n",
    "\n",
    "    # Guardar los resultados en un archivo JSON\n",
    "    metrics = {\n",
    "        'mean_TP': mean_TP,\n",
    "        'mean_TN': mean_TN,\n",
    "        'mean_FP': mean_FP,\n",
    "        'mean_FN': mean_FN,\n",
    "        'precision_avg': precision_avg,\n",
    "        'recall_avg': recall_avg,\n",
    "        'f1_score_avg': f1_score_avg,\n",
    "        'iou_avg': iou_avg\n",
    "    }\n",
    "    \n",
    "    json_file = os.path.join(trial_path, f\"trial_{trial_number}_metricas.json\")\n",
    "    with open(json_file, 'w') as f:\n",
    "        json.dump(metrics, f, indent=4)\n",
    "\n",
    "    print(f\"\\nResultados para el trial en {trial_path} han sido guardados en {json_file}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5919608",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def borrar_Figuras(trial_path):\n",
    "#     \"\"\"Eliminar la carpeta Figuras si existe dentro de trial_path.\"\"\"\n",
    "#     Figuras_path = os.path.join(trial_path, \"Figuras\")\n",
    "#     if os.path.exists(Figuras_path) and os.path.isdir(Figuras_path):\n",
    "#         shutil.rmtree(Figuras_path)\n",
    "#         print(f\"Carpeta 'Figuras' eliminada en: {trial_path}\")\n",
    "#     else:\n",
    "#         print(f\"No se encontró la carpeta 'Figuras' en: {trial_path}\")\n",
    "        \n",
    "# # Iterar sobre cada carpeta trial y borrar Figuras\n",
    "# for folder in os.listdir(ruta_resultados):\n",
    "#     trial_path = os.path.join(ruta_resultados, folder)\n",
    "#     if os.path.isdir(trial_path) and folder.startswith(\"trial_\") and folder.split(\"_\")[1].isdigit():\n",
    "#         borrar_Figuras(trial_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "daf31035",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/hpc22/computer_vision_colon/TFM/Entrenamiento/datasets/Polipos265_Detectron2FIX_YoloV8/test/labels\n",
      "models/Final/YoloV8_n_25_fix/trial_3/coordenadas_test\n",
      "\n",
      "Resultados para el trial en models/Final/YoloV8_n_25_fix/trial_3 han sido guardados en models/Final/YoloV8_n_25_fix/trial_3/trial_3_metricas.json\n",
      "/home/hpc22/computer_vision_colon/TFM/Entrenamiento/datasets/Polipos265_Detectron2FIX_YoloV8/test/labels\n",
      "models/Final/YoloV8_n_25_fix/trial_21/coordenadas_test\n",
      "\n",
      "Resultados para el trial en models/Final/YoloV8_n_25_fix/trial_21 han sido guardados en models/Final/YoloV8_n_25_fix/trial_21/trial_21_metricas.json\n",
      "/home/hpc22/computer_vision_colon/TFM/Entrenamiento/datasets/Polipos265_Detectron2FIX_YoloV8/test/labels\n",
      "models/Final/YoloV8_n_25_fix/trial_2/coordenadas_test\n",
      "\n",
      "Resultados para el trial en models/Final/YoloV8_n_25_fix/trial_2 han sido guardados en models/Final/YoloV8_n_25_fix/trial_2/trial_2_metricas.json\n",
      "/home/hpc22/computer_vision_colon/TFM/Entrenamiento/datasets/Polipos265_Detectron2FIX_YoloV8/test/labels\n",
      "models/Final/YoloV8_n_25_fix/trial_9/coordenadas_test\n",
      "\n",
      "Resultados para el trial en models/Final/YoloV8_n_25_fix/trial_9 han sido guardados en models/Final/YoloV8_n_25_fix/trial_9/trial_9_metricas.json\n",
      "/home/hpc22/computer_vision_colon/TFM/Entrenamiento/datasets/Polipos265_Detectron2FIX_YoloV8/test/labels\n",
      "models/Final/YoloV8_n_25_fix/trial_4/coordenadas_test\n",
      "\n",
      "Resultados para el trial en models/Final/YoloV8_n_25_fix/trial_4 han sido guardados en models/Final/YoloV8_n_25_fix/trial_4/trial_4_metricas.json\n",
      "/home/hpc22/computer_vision_colon/TFM/Entrenamiento/datasets/Polipos265_Detectron2FIX_YoloV8/test/labels\n",
      "models/Final/YoloV8_n_25_fix/trial_8/coordenadas_test\n",
      "\n",
      "Resultados para el trial en models/Final/YoloV8_n_25_fix/trial_8 han sido guardados en models/Final/YoloV8_n_25_fix/trial_8/trial_8_metricas.json\n",
      "/home/hpc22/computer_vision_colon/TFM/Entrenamiento/datasets/Polipos265_Detectron2FIX_YoloV8/test/labels\n",
      "models/Final/YoloV8_n_25_fix/trial_12/coordenadas_test\n",
      "\n",
      "Resultados para el trial en models/Final/YoloV8_n_25_fix/trial_12 han sido guardados en models/Final/YoloV8_n_25_fix/trial_12/trial_12_metricas.json\n",
      "/home/hpc22/computer_vision_colon/TFM/Entrenamiento/datasets/Polipos265_Detectron2FIX_YoloV8/test/labels\n",
      "models/Final/YoloV8_n_25_fix/trial_7/coordenadas_test\n",
      "\n",
      "Resultados para el trial en models/Final/YoloV8_n_25_fix/trial_7 han sido guardados en models/Final/YoloV8_n_25_fix/trial_7/trial_7_metricas.json\n",
      "/home/hpc22/computer_vision_colon/TFM/Entrenamiento/datasets/Polipos265_Detectron2FIX_YoloV8/test/labels\n",
      "models/Final/YoloV8_n_25_fix/trial_24/coordenadas_test\n",
      "\n",
      "Resultados para el trial en models/Final/YoloV8_n_25_fix/trial_24 han sido guardados en models/Final/YoloV8_n_25_fix/trial_24/trial_24_metricas.json\n",
      "/home/hpc22/computer_vision_colon/TFM/Entrenamiento/datasets/Polipos265_Detectron2FIX_YoloV8/test/labels\n",
      "models/Final/YoloV8_n_25_fix/trial_5/coordenadas_test\n",
      "\n",
      "Resultados para el trial en models/Final/YoloV8_n_25_fix/trial_5 han sido guardados en models/Final/YoloV8_n_25_fix/trial_5/trial_5_metricas.json\n",
      "/home/hpc22/computer_vision_colon/TFM/Entrenamiento/datasets/Polipos265_Detectron2FIX_YoloV8/test/labels\n",
      "models/Final/YoloV8_n_25_fix/trial_1/coordenadas_test\n",
      "\n",
      "Resultados para el trial en models/Final/YoloV8_n_25_fix/trial_1 han sido guardados en models/Final/YoloV8_n_25_fix/trial_1/trial_1_metricas.json\n",
      "/home/hpc22/computer_vision_colon/TFM/Entrenamiento/datasets/Polipos265_Detectron2FIX_YoloV8/test/labels\n",
      "models/Final/YoloV8_n_25_fix/trial_13/coordenadas_test\n",
      "\n",
      "Resultados para el trial en models/Final/YoloV8_n_25_fix/trial_13 han sido guardados en models/Final/YoloV8_n_25_fix/trial_13/trial_13_metricas.json\n",
      "/home/hpc22/computer_vision_colon/TFM/Entrenamiento/datasets/Polipos265_Detectron2FIX_YoloV8/test/labels\n",
      "models/Final/YoloV8_n_25_fix/trial_22/coordenadas_test\n",
      "\n",
      "Resultados para el trial en models/Final/YoloV8_n_25_fix/trial_22 han sido guardados en models/Final/YoloV8_n_25_fix/trial_22/trial_22_metricas.json\n",
      "/home/hpc22/computer_vision_colon/TFM/Entrenamiento/datasets/Polipos265_Detectron2FIX_YoloV8/test/labels\n",
      "models/Final/YoloV8_n_25_fix/trial_20/coordenadas_test\n",
      "\n",
      "Resultados para el trial en models/Final/YoloV8_n_25_fix/trial_20 han sido guardados en models/Final/YoloV8_n_25_fix/trial_20/trial_20_metricas.json\n",
      "/home/hpc22/computer_vision_colon/TFM/Entrenamiento/datasets/Polipos265_Detectron2FIX_YoloV8/test/labels\n",
      "models/Final/YoloV8_n_25_fix/trial_6/coordenadas_test\n",
      "\n",
      "Resultados para el trial en models/Final/YoloV8_n_25_fix/trial_6 han sido guardados en models/Final/YoloV8_n_25_fix/trial_6/trial_6_metricas.json\n",
      "/home/hpc22/computer_vision_colon/TFM/Entrenamiento/datasets/Polipos265_Detectron2FIX_YoloV8/test/labels\n",
      "models/Final/YoloV8_n_25_fix/trial_18/coordenadas_test\n",
      "\n",
      "Resultados para el trial en models/Final/YoloV8_n_25_fix/trial_18 han sido guardados en models/Final/YoloV8_n_25_fix/trial_18/trial_18_metricas.json\n",
      "/home/hpc22/computer_vision_colon/TFM/Entrenamiento/datasets/Polipos265_Detectron2FIX_YoloV8/test/labels\n",
      "models/Final/YoloV8_n_25_fix/trial_11/coordenadas_test\n",
      "\n",
      "Resultados para el trial en models/Final/YoloV8_n_25_fix/trial_11 han sido guardados en models/Final/YoloV8_n_25_fix/trial_11/trial_11_metricas.json\n",
      "/home/hpc22/computer_vision_colon/TFM/Entrenamiento/datasets/Polipos265_Detectron2FIX_YoloV8/test/labels\n",
      "models/Final/YoloV8_n_25_fix/trial_19/coordenadas_test\n",
      "\n",
      "Resultados para el trial en models/Final/YoloV8_n_25_fix/trial_19 han sido guardados en models/Final/YoloV8_n_25_fix/trial_19/trial_19_metricas.json\n",
      "/home/hpc22/computer_vision_colon/TFM/Entrenamiento/datasets/Polipos265_Detectron2FIX_YoloV8/test/labels\n",
      "models/Final/YoloV8_n_25_fix/trial_16/coordenadas_test\n",
      "\n",
      "Resultados para el trial en models/Final/YoloV8_n_25_fix/trial_16 han sido guardados en models/Final/YoloV8_n_25_fix/trial_16/trial_16_metricas.json\n",
      "/home/hpc22/computer_vision_colon/TFM/Entrenamiento/datasets/Polipos265_Detectron2FIX_YoloV8/test/labels\n",
      "models/Final/YoloV8_n_25_fix/trial_23/coordenadas_test\n",
      "\n",
      "Resultados para el trial en models/Final/YoloV8_n_25_fix/trial_23 han sido guardados en models/Final/YoloV8_n_25_fix/trial_23/trial_23_metricas.json\n",
      "/home/hpc22/computer_vision_colon/TFM/Entrenamiento/datasets/Polipos265_Detectron2FIX_YoloV8/test/labels\n",
      "models/Final/YoloV8_n_25_fix/trial_10/coordenadas_test\n",
      "\n",
      "Resultados para el trial en models/Final/YoloV8_n_25_fix/trial_10 han sido guardados en models/Final/YoloV8_n_25_fix/trial_10/trial_10_metricas.json\n",
      "/home/hpc22/computer_vision_colon/TFM/Entrenamiento/datasets/Polipos265_Detectron2FIX_YoloV8/test/labels\n",
      "models/Final/YoloV8_n_25_fix/trial_0/coordenadas_test\n",
      "\n",
      "Resultados para el trial en models/Final/YoloV8_n_25_fix/trial_0 han sido guardados en models/Final/YoloV8_n_25_fix/trial_0/trial_0_metricas.json\n",
      "/home/hpc22/computer_vision_colon/TFM/Entrenamiento/datasets/Polipos265_Detectron2FIX_YoloV8/test/labels\n",
      "models/Final/YoloV8_n_25_fix/trial_15/coordenadas_test\n",
      "\n",
      "Resultados para el trial en models/Final/YoloV8_n_25_fix/trial_15 han sido guardados en models/Final/YoloV8_n_25_fix/trial_15/trial_15_metricas.json\n",
      "/home/hpc22/computer_vision_colon/TFM/Entrenamiento/datasets/Polipos265_Detectron2FIX_YoloV8/test/labels\n",
      "models/Final/YoloV8_n_25_fix/trial_17/coordenadas_test\n",
      "\n",
      "Resultados para el trial en models/Final/YoloV8_n_25_fix/trial_17 han sido guardados en models/Final/YoloV8_n_25_fix/trial_17/trial_17_metricas.json\n",
      "/home/hpc22/computer_vision_colon/TFM/Entrenamiento/datasets/Polipos265_Detectron2FIX_YoloV8/test/labels\n",
      "models/Final/YoloV8_n_25_fix/trial_14/coordenadas_test\n",
      "\n",
      "Resultados para el trial en models/Final/YoloV8_n_25_fix/trial_14 han sido guardados en models/Final/YoloV8_n_25_fix/trial_14/trial_14_metricas.json\n"
     ]
    }
   ],
   "source": [
    "# Iterar sobre cada carpeta trial y procesar\n",
    "for folder in os.listdir(ruta_resultados):\n",
    "    trial_path = os.path.join(ruta_resultados, folder)\n",
    "    if os.path.isdir(trial_path) and folder.startswith(\"trial_\") and folder.split(\"_\")[1].isdigit():\n",
    "        evaluar_trial(trial_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d027f0d0",
   "metadata": {},
   "source": [
    "**Juntamos todos los json de las metricas**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "114e7fea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Métricas de todos los trials guardadas en models/YoloV8_n_25_Fix_OLD/evaluacion.json\n"
     ]
    }
   ],
   "source": [
    "# Contar el número de carpetas que siguen el patrón \"trial_\"\n",
    "trial_folders = [folder for folder in os.listdir(ruta_resultados) if folder.startswith(\"trial_\") and folder.split(\"_\")[1].isdigit()]\n",
    "n_trials = len(trial_folders)\n",
    "\n",
    "# Crear una lista para almacenar todas las métricas\n",
    "all_metrics = []\n",
    "\n",
    "# Recorrer todas las carpetas de trials y leer los archivos JSON de métricas\n",
    "for trial_num in range(n_trials):\n",
    "    trial_dir = os.path.join(ruta_resultados, f\"trial_{trial_num}\")\n",
    "    metrics_path = os.path.join(trial_dir, f\"trial_{trial_num}_metricas.json\")\n",
    "    if os.path.exists(metrics_path):\n",
    "        with open(metrics_path, 'r') as f:\n",
    "            trial_metrics = json.load(f)\n",
    "            trial_metrics[\"trial_number\"] = trial_num  # Añadir el número del trial a las métricas\n",
    "            all_metrics.append(trial_metrics)\n",
    "\n",
    "# Guardar todas las métricas en un archivo JSON\n",
    "evaluacion_path = os.path.join(ruta_resultados, \"evaluacion.json\")\n",
    "with open(evaluacion_path, 'w') as f:\n",
    "    json.dump(all_metrics, f, indent=2)\n",
    "\n",
    "print(f\"Métricas de todos los trials guardadas en {evaluacion_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7c3c6308",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 19: Weighted Score = 0.8828438653400437\n",
      "Trial 5: Weighted Score = 0.8608503618690455\n",
      "Trial 4: Weighted Score = 0.8557497784360885\n",
      "Trial 22: Weighted Score = 0.8498506759543574\n",
      "Trial 14: Weighted Score = 0.8361514229151755\n",
      "Trial 1: Weighted Score = 0.8347559648312743\n",
      "Trial 15: Weighted Score = 0.8330633407576643\n",
      "Trial 9: Weighted Score = 0.8250452055593901\n",
      "Trial 18: Weighted Score = 0.8247714676312701\n",
      "Trial 10: Weighted Score = 0.8240136782275047\n",
      "Trial 7: Weighted Score = 0.821220675957069\n",
      "Trial 12: Weighted Score = 0.8195839043911846\n",
      "Trial 24: Weighted Score = 0.816776069062496\n",
      "Trial 2: Weighted Score = 0.8081135172297598\n",
      "Trial 21: Weighted Score = 0.7966791673431348\n",
      "Trial 13: Weighted Score = 0.7896223074062703\n",
      "Trial 6: Weighted Score = 0.7882793404156524\n",
      "Trial 3: Weighted Score = 0.781403573227101\n",
      "Trial 20: Weighted Score = 0.7786397291135185\n",
      "Trial 23: Weighted Score = 0.7696108270367885\n",
      "Trial 8: Weighted Score = 0.7513854050945894\n",
      "Trial 0: Weighted Score = 0.7512410610846881\n",
      "Trial 17: Weighted Score = 0.6597444256397187\n",
      "Trial 11: Weighted Score = 0.6390179389078031\n",
      "Trial 16: Weighted Score = 0.4354793374134674\n",
      "Lista de trials ordenados guardada en models/YoloV8_n_25_Fix_OLD/sorted_trials.json\n"
     ]
    }
   ],
   "source": [
    "# Leer el archivo JSON\n",
    "with open(evaluacion_path, 'r') as f:\n",
    "    metrics_data = json.load(f)\n",
    "\n",
    "# Definir pesos para cada métrica (puedes ajustar los pesos según tu criterio)\n",
    "weights = {\n",
    "    \"precision_avg\": 0.25,\n",
    "    \"recall_avg\": 0.25,\n",
    "    \"f1_score_avg\": 0.25,\n",
    "    \"iou_avg\": 0.25\n",
    "}\n",
    "\n",
    "# Crear una lista con los trials y sus medias ponderadas\n",
    "trials_with_scores = []\n",
    "\n",
    "for trial in metrics_data:\n",
    "    precision = trial.get(\"precision_avg\", 0)\n",
    "    recall = trial.get(\"recall_avg\", 0)\n",
    "    f1_score = trial.get(\"f1_score_avg\", 0)\n",
    "    iou = trial.get(\"iou_avg\", 0)\n",
    "    \n",
    "    # Calcular la media ponderada\n",
    "    weighted_score = (\n",
    "        weights[\"precision_avg\"] * precision +\n",
    "        weights[\"recall_avg\"] * recall +\n",
    "        weights[\"f1_score_avg\"] * f1_score +\n",
    "        weights[\"iou_avg\"] * iou\n",
    "    )\n",
    "    \n",
    "    # Añadir a la lista\n",
    "    trials_with_scores.append({\n",
    "        \"trial_number\": trial[\"trial_number\"],\n",
    "        \"weighted_score\": weighted_score\n",
    "    })\n",
    "\n",
    "# Ordenar los trials por la media ponderada de mayor a menor\n",
    "sorted_trials = sorted(trials_with_scores, key=lambda x: x[\"weighted_score\"], reverse=True)\n",
    "\n",
    "# Mostrar la lista ordenada\n",
    "for trial in sorted_trials:\n",
    "    print(f\"Trial {trial['trial_number']}: Weighted Score = {trial['weighted_score']}\")\n",
    "\n",
    "# Si quieres guardar el resultado en un archivo JSON\n",
    "sorted_trials_path = os.path.join(os.path.dirname(evaluacion_path), \"sorted_trials.json\")\n",
    "with open(sorted_trials_path, 'w') as f:\n",
    "    json.dump(sorted_trials, f, indent=2)\n",
    "\n",
    "print(f\"Lista de trials ordenados guardada en {sorted_trials_path}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6db395ab",
   "metadata": {},
   "source": [
    "**Creamos  un json final con toda la información**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "af4c2bb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Leer los archivos JSON\n",
    "with open(evaluacion_path, 'r') as f:\n",
    "    evaluacion_data = json.load(f)\n",
    "\n",
    "with open(sorted_trials_path, 'r') as f:\n",
    "    sorted_trials_data = json.load(f)\n",
    "\n",
    "with open(all_metrics_path, 'r') as f:\n",
    "    all_metrics_data = json.load(f)\n",
    "\n",
    "# Crear un diccionario para acceder rápidamente a la información de sorted_trials\n",
    "sorted_trials_dict = {trial['trial_number']: trial['weighted_score'] for trial in sorted_trials_data}\n",
    "\n",
    "# Crear un diccionario para acceder rápidamente a la información de all_metrics\n",
    "all_metrics_dict = {trial['Trial']: trial for trial in all_metrics_data}\n",
    "\n",
    "# Obtener la información común del primer elemento de all_metrics_data\n",
    "if all_metrics_data:\n",
    "    common_info = {\n",
    "        \"Dataset\": all_metrics_data[0].get(\"Dataset\", \"\"),\n",
    "        \"Feedback\": all_metrics_data[0].get(\"Feedback\", \"\"),\n",
    "        \"Pre-Trained_Weights\": all_metrics_data[0].get(\"Pre-Trained_Weights\", \"\")\n",
    "    }\n",
    "else:\n",
    "    common_info = {\n",
    "        \"Dataset\": \"\",\n",
    "        \"Feedback\": \"\",\n",
    "        \"Pre-Trained_Weights\": \"\"\n",
    "    }\n",
    "\n",
    "# Crear el archivo de salida\n",
    "resultados = []\n",
    "\n",
    "# Ordenar los trial_numbers basados en sorted_trials_dict\n",
    "sorted_trial_numbers = sorted(sorted_trials_dict.keys())\n",
    "\n",
    "# Combinar la información\n",
    "for trial_number in sorted_trial_numbers:\n",
    "    # Buscar la información de evaluación y métricas\n",
    "    evaluation_info = next((item for item in evaluacion_data if item[\"trial_number\"] == trial_number), {})\n",
    "    metrics_info = all_metrics_dict.get(trial_number, {})\n",
    "    \n",
    "    # Crear el objeto para el trial actual\n",
    "    trial_info = {\n",
    "        \"trial_number\": trial_number,\n",
    "        \"hyperparameters\": metrics_info.get(\"hyperparameters\", {}),\n",
    "        \"metrics\": metrics_info.get(\"metrics\", {}),\n",
    "        \"evaluation\": evaluation_info,\n",
    "        \"weighted_score\": sorted_trials_dict[trial_number]\n",
    "    }\n",
    "    \n",
    "    # Añadir la información común y la información del trial a la lista de resultados\n",
    "    resultados.append({**common_info, **trial_info})\n",
    "\n",
    "# Guardar el resultado en el archivo Resultados.json\n",
    "resultados_path = os.path.join(os.path.dirname(trial_dir), \"Resultados.json\")\n",
    "with open(resultados_path, 'w') as f:\n",
    "    json.dump(resultados, f, indent=2)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a89f87ea",
   "metadata": {},
   "source": [
    "**Resultados ordenados por las mejores metricas**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a071444",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Leer los archivos JSON\n",
    "with open(evaluacion_path, 'r') as f:\n",
    "    evaluacion_data = json.load(f)\n",
    "\n",
    "with open(sorted_trials_path, 'r') as f:\n",
    "    sorted_trials_data = json.load(f)\n",
    "\n",
    "with open(all_metrics_path, 'r') as f:\n",
    "    all_metrics_data = json.load(f)\n",
    "\n",
    "with open(inference_times_path, 'r') as f:\n",
    "    inference_times_data = json.load(f)\n",
    "\n",
    "# Crear un diccionario para acceder rápidamente a la información de sorted_trials\n",
    "sorted_trials_dict = {trial['trial_number']: trial['weighted_score'] for trial in sorted_trials_data}\n",
    "\n",
    "# Crear un diccionario para acceder rápidamente a la información de all_metrics\n",
    "all_metrics_dict = {trial['Trial']: trial for trial in all_metrics_data}\n",
    "\n",
    "# Crear un diccionario para acceder rápidamente a la información de inference_times\n",
    "inference_times_dict = {trial['trial_number']: trial['inference_time'] for trial in inference_times_data}\n",
    "\n",
    "# Obtener la información común del primer elemento de all_metrics_data\n",
    "if all_metrics_data:\n",
    "    common_info = {\n",
    "        \"Dataset\": all_metrics_data[0].get(\"Dataset\", \"\"),\n",
    "        \"Feedback\": all_metrics_data[0].get(\"Feedback\", \"\"),\n",
    "        \"Pre-Trained_Weights\": all_metrics_data[0].get(\"Pre-Trained_Weights\", \"\")\n",
    "    }\n",
    "else:\n",
    "    common_info = {\n",
    "        \"Dataset\": \"\",\n",
    "        \"Feedback\": \"\",\n",
    "        \"Pre-Trained_Weights\": \"\"\n",
    "    }\n",
    "\n",
    "# Crear el archivo de salida\n",
    "resultados_ordenados = []\n",
    "\n",
    "# Extraer los trial_numbers en el orden exacto en el que aparecen en sorted_trials_data\n",
    "sorted_trial_numbers = [trial['trial_number'] for trial in sorted_trials_data]\n",
    "\n",
    "# Combinar la información\n",
    "for trial_number in sorted_trial_numbers:\n",
    "    # Buscar la información de evaluación y métricas\n",
    "    evaluation_info = next((item for item in evaluacion_data if item[\"trial_number\"] == trial_number), {})\n",
    "    metrics_info = all_metrics_dict.get(trial_number, {})\n",
    "    inference_time = inference_times_dict.get(trial_number, 0)  # Obtener el tiempo de inferencia\n",
    "\n",
    "    # Crear el objeto para el trial actual\n",
    "    trial_info = {\n",
    "        \"trial_number\": trial_number,\n",
    "        \"hyperparameters\": metrics_info.get(\"hyperparameters\", {}),\n",
    "        \"metrics\": metrics_info.get(\"metrics\", {}),\n",
    "        \"evaluation\": evaluation_info,\n",
    "        \"weighted_score\": sorted_trials_dict[trial_number],\n",
    "        \"inference_time\": inference_time  # Añadir el tiempo de inferencia\n",
    "    }\n",
    "\n",
    "    # Añadir la información común y la información del trial a la lista de resultados\n",
    "    resultados_ordenados.append({**common_info, **trial_info})\n",
    "\n",
    "# Guardar el resultado en el archivo con un nombre dinámico\n",
    "resultados_path = os.path.join(os.path.dirname(trial_dir), \"Resultados_ordenados_metricas.json\")\n",
    "with open(resultados_path, 'w') as f:\n",
    "    json.dump(resultados_ordenados, f, indent=2)\n",
    "\n",
    "print(f\"Archivo Resultados_ordenados_metricas.json guardado en {resultados_path}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7871c2f5",
   "metadata": {},
   "source": [
    "**Creamos un criterio por el que obtenemos el mejor modelo de estos trials, segun el teimpo de inferencia**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a664850",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "\n",
    "# Leer los archivos JSON\n",
    "with open(evaluacion_path, 'r') as f:\n",
    "    evaluacion_data = json.load(f)\n",
    "\n",
    "with open(sorted_trials_path, 'r') as f:\n",
    "    sorted_trials_data = json.load(f)\n",
    "\n",
    "with open(all_metrics_path, 'r') as f:\n",
    "    all_metrics_data = json.load(f)\n",
    "\n",
    "with open(inference_times_path, 'r') as f:\n",
    "    inference_times_data = json.load(f)\n",
    "\n",
    "# Crear un diccionario para acceder rápidamente a la información de sorted_trials\n",
    "sorted_trials_dict = {trial['trial_number']: trial['weighted_score'] for trial in sorted_trials_data}\n",
    "\n",
    "# Crear un diccionario para acceder rápidamente a la información de all_metrics\n",
    "all_metrics_dict = {trial['Trial']: trial for trial in all_metrics_data}\n",
    "\n",
    "# Crear un diccionario para acceder rápidamente a la información de inference_times\n",
    "inference_times_dict = {trial['trial_number']: trial['inference_time'] for trial in inference_times_data}\n",
    "\n",
    "# Obtener la información común del primer elemento de all_metrics_data\n",
    "if all_metrics_data:\n",
    "    common_info = {\n",
    "        \"Dataset\": all_metrics_data[0].get(\"Dataset\", \"\"),\n",
    "        \"Feedback\": all_metrics_data[0].get(\"Feedback\", \"\"),\n",
    "        \"Pre-Trained_Weights\": all_metrics_data[0].get(\"Pre-Trained_Weights\", \"\")\n",
    "    }\n",
    "else:\n",
    "    common_info = {\n",
    "        \"Dataset\": \"\",\n",
    "        \"Feedback\": \"\",\n",
    "        \"Pre-Trained_Weights\": \"\"\n",
    "    }\n",
    "\n",
    "# Crear el archivo de salida\n",
    "resultados_ordenados = []\n",
    "\n",
    "# Extraer los trial_numbers en el orden exacto en el que aparecen en sorted_trials_data\n",
    "sorted_trial_numbers = [trial['trial_number'] for trial in sorted_trials_data]\n",
    "\n",
    "# Combinar la información\n",
    "for trial_number in sorted_trial_numbers:\n",
    "    # Buscar la información de evaluación y métricas\n",
    "    evaluation_info = next((item for item in evaluacion_data if item[\"trial_number\"] == trial_number), {})\n",
    "    metrics_info = all_metrics_dict.get(trial_number, {})\n",
    "    inference_time = inference_times_dict.get(trial_number, 0)  # Obtener el tiempo de inferencia\n",
    "\n",
    "    # Crear el objeto para el trial actual\n",
    "    trial_info = {\n",
    "        \"trial_number\": trial_number,\n",
    "        \"hyperparameters\": metrics_info.get(\"hyperparameters\", {}),\n",
    "        \"metrics\": metrics_info.get(\"metrics\", {}),\n",
    "        \"evaluation\": evaluation_info,\n",
    "        \"weighted_score\": sorted_trials_dict[trial_number],\n",
    "        \"inference_time\": inference_time  # Añadir el tiempo de inferencia\n",
    "    }\n",
    "\n",
    "    # Añadir la información común y la información del trial a la lista de resultados\n",
    "    resultados_ordenados.append({**common_info, **trial_info})\n",
    "\n",
    "# Ordenar los resultados por tiempo de inferencia (menor a mayor)\n",
    "resultados_ordenados.sort(key=lambda x: x[\"inference_time\"])\n",
    "\n",
    "# Guardar el resultado en el archivo con un nombre dinámico\n",
    "resultados_path = os.path.join(os.path.dirname(trial_dir), \"Resultados_ordenados_time.json\")\n",
    "with open(resultados_path, 'w') as f:\n",
    "    json.dump(resultados_ordenados, f, indent=2)\n",
    "\n",
    "print(f\"Archivo Resultados_ordenados_metricas.json guardado en {resultados_path}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (computer_vision_colon)",
   "language": "python",
   "name": "computer_vision_colon"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
