{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/JorgeAnsotegui/TFM/blob/main/Metricas/MetricasLast.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "JA42tCveEewU",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1f6de1cd-c3c2-4c2f-c482-611d4043fda9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting ultralytics\n",
            "  Downloading ultralytics-8.2.79-py3-none-any.whl.metadata (41 kB)\n",
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/41.3 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m \u001b[32m41.0/41.3 kB\u001b[0m \u001b[31m61.8 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m41.3/41.3 kB\u001b[0m \u001b[31m637.4 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy<2.0.0,>=1.23.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (1.26.4)\n",
            "Requirement already satisfied: matplotlib>=3.3.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (3.7.1)\n",
            "Requirement already satisfied: opencv-python>=4.6.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (4.10.0.84)\n",
            "Requirement already satisfied: pillow>=7.1.2 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (9.4.0)\n",
            "Requirement already satisfied: pyyaml>=5.3.1 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (6.0.2)\n",
            "Requirement already satisfied: requests>=2.23.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (2.32.3)\n",
            "Requirement already satisfied: scipy>=1.4.1 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (1.13.1)\n",
            "Requirement already satisfied: torch>=1.8.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (2.3.1+cu121)\n",
            "Requirement already satisfied: torchvision>=0.9.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (0.18.1+cu121)\n",
            "Requirement already satisfied: tqdm>=4.64.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (4.66.5)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from ultralytics) (5.9.5)\n",
            "Requirement already satisfied: py-cpuinfo in /usr/local/lib/python3.10/dist-packages (from ultralytics) (9.0.0)\n",
            "Requirement already satisfied: pandas>=1.1.4 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (2.1.4)\n",
            "Requirement already satisfied: seaborn>=0.11.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (0.13.1)\n",
            "Collecting ultralytics-thop>=2.0.0 (from ultralytics)\n",
            "  Downloading ultralytics_thop-2.0.5-py3-none-any.whl.metadata (8.9 kB)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.0->ultralytics) (1.2.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.0->ultralytics) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.0->ultralytics) (4.53.1)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.0->ultralytics) (1.4.5)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.0->ultralytics) (24.1)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.0->ultralytics) (3.1.2)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.0->ultralytics) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.1.4->ultralytics) (2024.1)\n",
            "Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.1.4->ultralytics) (2024.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.23.0->ultralytics) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.23.0->ultralytics) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.23.0->ultralytics) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.23.0->ultralytics) (2024.7.4)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->ultralytics) (3.15.4)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->ultralytics) (4.12.2)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->ultralytics) (1.13.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->ultralytics) (3.3)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->ultralytics) (3.1.4)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->ultralytics) (2024.6.1)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.1.105 (from torch>=1.8.0->ultralytics)\n",
            "  Using cached nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.1.105 (from torch>=1.8.0->ultralytics)\n",
            "  Using cached nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.1.105 (from torch>=1.8.0->ultralytics)\n",
            "  Using cached nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cudnn-cu12==8.9.2.26 (from torch>=1.8.0->ultralytics)\n",
            "  Using cached nvidia_cudnn_cu12-8.9.2.26-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cublas-cu12==12.1.3.1 (from torch>=1.8.0->ultralytics)\n",
            "  Using cached nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cufft-cu12==11.0.2.54 (from torch>=1.8.0->ultralytics)\n",
            "  Using cached nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-curand-cu12==10.3.2.106 (from torch>=1.8.0->ultralytics)\n",
            "  Using cached nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cusolver-cu12==11.4.5.107 (from torch>=1.8.0->ultralytics)\n",
            "  Using cached nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cusparse-cu12==12.1.0.106 (from torch>=1.8.0->ultralytics)\n",
            "  Using cached nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-nccl-cu12==2.20.5 (from torch>=1.8.0->ultralytics)\n",
            "  Using cached nvidia_nccl_cu12-2.20.5-py3-none-manylinux2014_x86_64.whl.metadata (1.8 kB)\n",
            "Collecting nvidia-nvtx-cu12==12.1.105 (from torch>=1.8.0->ultralytics)\n",
            "  Using cached nvidia_nvtx_cu12-12.1.105-py3-none-manylinux1_x86_64.whl.metadata (1.7 kB)\n",
            "Requirement already satisfied: triton==2.3.1 in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->ultralytics) (2.3.1)\n",
            "Collecting nvidia-nvjitlink-cu12 (from nvidia-cusolver-cu12==11.4.5.107->torch>=1.8.0->ultralytics)\n",
            "  Using cached nvidia_nvjitlink_cu12-12.6.20-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.7->matplotlib>=3.3.0->ultralytics) (1.16.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.8.0->ultralytics) (2.1.5)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.8.0->ultralytics) (1.3.0)\n",
            "Downloading ultralytics-8.2.79-py3-none-any.whl (869 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m869.1/869.1 kB\u001b[0m \u001b[31m12.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hUsing cached nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl (410.6 MB)\n",
            "Using cached nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (14.1 MB)\n",
            "Using cached nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (23.7 MB)\n",
            "Using cached nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (823 kB)\n",
            "Using cached nvidia_cudnn_cu12-8.9.2.26-py3-none-manylinux1_x86_64.whl (731.7 MB)\n",
            "Using cached nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl (121.6 MB)\n",
            "Using cached nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl (56.5 MB)\n",
            "Using cached nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl (124.2 MB)\n",
            "Using cached nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl (196.0 MB)\n",
            "Using cached nvidia_nccl_cu12-2.20.5-py3-none-manylinux2014_x86_64.whl (176.2 MB)\n",
            "Using cached nvidia_nvtx_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (99 kB)\n",
            "Downloading ultralytics_thop-2.0.5-py3-none-any.whl (25 kB)\n",
            "Using cached nvidia_nvjitlink_cu12-12.6.20-py3-none-manylinux2014_x86_64.whl (19.7 MB)\n",
            "Installing collected packages: nvidia-nvtx-cu12, nvidia-nvjitlink-cu12, nvidia-nccl-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12, ultralytics-thop, ultralytics\n",
            "Successfully installed nvidia-cublas-cu12-12.1.3.1 nvidia-cuda-cupti-cu12-12.1.105 nvidia-cuda-nvrtc-cu12-12.1.105 nvidia-cuda-runtime-cu12-12.1.105 nvidia-cudnn-cu12-8.9.2.26 nvidia-cufft-cu12-11.0.2.54 nvidia-curand-cu12-10.3.2.106 nvidia-cusolver-cu12-11.4.5.107 nvidia-cusparse-cu12-12.1.0.106 nvidia-nccl-cu12-2.20.5 nvidia-nvjitlink-cu12-12.6.20 nvidia-nvtx-cu12-12.1.105 ultralytics-8.2.79 ultralytics-thop-2.0.5\n"
          ]
        }
      ],
      "source": [
        "# Install the ultralytics package using pip\n",
        "!pip install ultralytics"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from ultralytics import YOLO\n",
        "from matplotlib import pyplot as plt\n",
        "from PIL import Image"
      ],
      "metadata": {
        "id": "XW63ce5WFBFc"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Conectar Colab a Google Drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MpAQT_BCFCTW",
        "outputId": "44b8524d-0eb5-4819-94b0-724a02a3e32f"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import zipfile\n",
        "\n",
        "# Función para crear carpetas si no existen\n",
        "def create_directories_if_not_exist(*directories):\n",
        "    for directory in directories:\n",
        "        os.makedirs(directory, exist_ok=True)\n",
        "\n",
        "# Ruta al archivo ZIP y la ruta de destino\n",
        "zip_file_path = '/content/drive/MyDrive/TFM/models/YoloV8_250Epoch_V1.zip'\n",
        "output_directory = '/content/models/'\n",
        "\n",
        "# Crear el directorio de salida si no existe\n",
        "create_directories_if_not_exist(output_directory)\n",
        "\n",
        "# Descomprimir el archivo ZIP en el directorio de salida\n",
        "with zipfile.ZipFile(zip_file_path, 'r') as zip_ref:\n",
        "    zip_ref.extractall(output_directory)\n",
        "\n",
        "print(f\"Archivo descomprimido en: {output_directory}\")\n"
      ],
      "metadata": {
        "id": "A6nGAa1oFDAp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import shutil\n",
        "import os\n",
        "\n",
        "# Función para borrar directorios, incluso si tienen contenido\n",
        "def delete_directory(directory):\n",
        "    if os.path.exists(directory):\n",
        "        shutil.rmtree(directory)\n",
        "        print(f\"Directorio '{directory}' ha sido eliminado.\")\n",
        "    else:\n",
        "        print(f\"El directorio '{directory}' no existe.\")\n",
        "\n",
        "# Especifica la ruta del directorio que quieres borrar\n",
        "directory_to_delete = '/content/models/YoloV8_250Epoch_V1/trial_03'\n",
        "\n",
        "# Llamada a la función para borrar el directorio\n",
        "delete_directory(directory_to_delete)\n"
      ],
      "metadata": {
        "id": "Ffwq6JIYGqh8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Ruta al archivo CSV\n",
        "csv_file_path = '/content/models/YoloV8_250Epoch_V1/trial_1/results.csv'\n",
        "\n",
        "# Leer el archivo CSV\n",
        "df = pd.read_csv(csv_file_path)\n",
        "\n",
        "# Imprimir los nombres de las columnas\n",
        "print(\"Nombres de las columnas en el archivo CSV:\")\n",
        "print(df.columns.tolist())\n"
      ],
      "metadata": {
        "id": "Jpbv9IEvLB66"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import glob\n",
        "\n",
        "def clean_column_names(df):\n",
        "    # Eliminar espacios en blanco al inicio y al final de los nombres de las columnas\n",
        "    df.columns = df.columns.str.strip()\n",
        "    return df\n",
        "\n",
        "def plot_metrics_from_trials(base_directory):\n",
        "    # Listar todas las carpetas de trials\n",
        "    trial_folders = glob.glob(os.path.join(base_directory, 'trial_*'))\n",
        "\n",
        "    # Inicializar listas para almacenar los datos de todas las métricas\n",
        "    precision_data = []\n",
        "    recall_data = []\n",
        "    map50_data = []\n",
        "\n",
        "    # Recorrer cada carpeta de trial\n",
        "    for folder in trial_folders:\n",
        "        results_file = os.path.join(folder, 'results.csv')\n",
        "        if os.path.exists(results_file):\n",
        "            # Leer el archivo CSV\n",
        "            df = pd.read_csv(results_file)\n",
        "\n",
        "            # Limpiar nombres de columnas\n",
        "            df = clean_column_names(df)\n",
        "\n",
        "            # Imprimir los nombres de las columnas para depuración\n",
        "            print(f\"Columnas en '{results_file}': {df.columns.tolist()}\")\n",
        "\n",
        "            # Intentar guardar las columnas de interés\n",
        "            try:\n",
        "                precision_data.append(df['metrics/precision(M)'].values)\n",
        "                recall_data.append(df['metrics/recall(M)'].values)\n",
        "                map50_data.append(df['metrics/mAP50(M)'].values)\n",
        "            except KeyError as e:\n",
        "                print(f\"Columna no encontrada: {e}\")\n",
        "\n",
        "    # Convertir listas a DataFrames para facilitar el cálculo de la media\n",
        "    precision_df = pd.DataFrame(precision_data).transpose()\n",
        "    recall_df = pd.DataFrame(recall_data).transpose()\n",
        "    map50_df = pd.DataFrame(map50_data).transpose()\n",
        "\n",
        "    # Calcular las medias\n",
        "    precision_mean = precision_df.mean(axis=1)\n",
        "    recall_mean = recall_df.mean(axis=1)\n",
        "    map50_mean = map50_df.mean(axis=1)\n",
        "\n",
        "    # Plotear las métricas\n",
        "    fig, axs = plt.subplots(3, 1, figsize=(10, 15))\n",
        "\n",
        "    # Plot Precision\n",
        "    for trial_data in precision_data:\n",
        "        axs[0].plot(trial_data, color='lightblue', alpha=0.5)\n",
        "    axs[0].plot(precision_mean, color='darkblue', label='Mean Precision', linewidth=2)\n",
        "    axs[0].set_title('Precision Over Epochs')\n",
        "    axs[0].set_xlabel('Epochs')\n",
        "    axs[0].set_ylabel('Precision')\n",
        "    axs[0].legend()\n",
        "\n",
        "    # Plot Recall\n",
        "    for trial_data in recall_data:\n",
        "        axs[1].plot(trial_data, color='lightgreen', alpha=0.5)\n",
        "    axs[1].plot(recall_mean, color='darkgreen', label='Mean Recall', linewidth=2)\n",
        "    axs[1].set_title('Recall Over Epochs')\n",
        "    axs[1].set_xlabel('Epochs')\n",
        "    axs[1].set_ylabel('Recall')\n",
        "    axs[1].legend()\n",
        "\n",
        "    # Plot mAP50\n",
        "    for trial_data in map50_data:\n",
        "        axs[2].plot(trial_data, color='lightcoral', alpha=0.5)\n",
        "    axs[2].plot(map50_mean, color='darkred', label='Mean mAP50', linewidth=2)\n",
        "    axs[2].set_title('mAP50 Over Epochs')\n",
        "    axs[2].set_xlabel('Epochs')\n",
        "    axs[2].set_ylabel('mAP50')\n",
        "    axs[2].legend()\n",
        "\n",
        "    # Ajustar el espaciado\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "# Uso de la función\n",
        "base_directory = '/content/models/YoloV8_250Epoch_V1'\n",
        "plot_metrics_from_trials(base_directory)\n"
      ],
      "metadata": {
        "id": "a9kOp_ugLUGl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import glob\n",
        "import os\n",
        "\n",
        "def calculate_weighted_mean(last_epoch_metrics):\n",
        "    \"\"\"\n",
        "    Calcula la media ponderada de las métricas de precisión, recall y mAP50.\n",
        "    Los pesos para cada métrica son 1 en este caso, pero puedes ajustarlos si es necesario.\n",
        "    \"\"\"\n",
        "    # Pesos de las métricas (se asume un peso igual para cada métrica en este caso)\n",
        "    weights = {'metrics/precision(M)': 1, 'metrics/recall(M)': 1, 'metrics/mAP50(M)': 1}\n",
        "\n",
        "    weighted_sum = 0\n",
        "    total_weight = 0\n",
        "\n",
        "    for metric, weight in weights.items():\n",
        "        if metric in last_epoch_metrics:\n",
        "            weighted_sum += last_epoch_metrics[metric] * weight\n",
        "            total_weight += weight\n",
        "\n",
        "    return weighted_sum / total_weight if total_weight > 0 else None\n",
        "\n",
        "def analyze_trials(base_directory):\n",
        "    trial_metrics = {}\n",
        "\n",
        "    # Listar todas las carpetas de trials\n",
        "    trial_folders = glob.glob(os.path.join(base_directory, 'trial_*'))\n",
        "\n",
        "    # Recorrer cada carpeta de trial\n",
        "    for folder in trial_folders:\n",
        "        results_file = os.path.join(folder, 'results.csv')\n",
        "        if os.path.exists(results_file):\n",
        "            # Leer el archivo CSV\n",
        "            df = pd.read_csv(results_file)\n",
        "\n",
        "            # Limpiar nombres de columnas\n",
        "            df = clean_column_names(df)\n",
        "\n",
        "            # Obtener el último epoch\n",
        "            last_epoch = df.iloc[-1]\n",
        "\n",
        "            # Extraer las métricas del último epoch\n",
        "            last_epoch_metrics = {\n",
        "                'metrics/precision(M)': last_epoch.get('metrics/precision(M)', None),\n",
        "                'metrics/recall(M)': last_epoch.get('metrics/recall(M)', None),\n",
        "                'metrics/mAP50(M)': last_epoch.get('metrics/mAP50(M)', None)\n",
        "            }\n",
        "\n",
        "            # Calcular la media ponderada\n",
        "            weighted_mean = calculate_weighted_mean(last_epoch_metrics)\n",
        "\n",
        "            # Guardar en el diccionario con el número del trial como clave\n",
        "            trial_number = int(os.path.basename(folder).split('_')[1])\n",
        "            trial_metrics[trial_number] = weighted_mean\n",
        "\n",
        "    # Ordenar los trials por la media ponderada (de mayor a menor) y obtener los 3 mejores\n",
        "    sorted_trials = sorted(trial_metrics.items(), key=lambda x: x[1], reverse=True)\n",
        "    best_3_trials = [trial[0] for trial in sorted_trials[:3]]\n",
        "\n",
        "    # Imprimir resultados\n",
        "    print(\"Media ponderada de las métricas para cada trial:\")\n",
        "    for trial_number, mean in trial_metrics.items():\n",
        "        print(f\"Trial {trial_number}: {mean}\")\n",
        "\n",
        "    print(\"\\nLos 3 mejores trials en orden:\")\n",
        "    print(best_3_trials)\n",
        "\n",
        "    return trial_metrics, best_3_trials\n",
        "\n",
        "# Usar la función\n",
        "base_directory = '/content/models/YoloV8_250Epoch_V1'\n",
        "trial_metrics, best_3_trials = analyze_trials(base_directory)\n"
      ],
      "metadata": {
        "id": "aOm1ZsDYMH0b"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import glob\n",
        "\n",
        "def clean_column_names(df):\n",
        "    # Eliminar espacios en blanco al inicio y al final de los nombres de las columnas\n",
        "    df.columns = df.columns.str.strip()\n",
        "    return df\n",
        "\n",
        "def plot_metrics_from_trials(base_directory, selected_trials):\n",
        "    # Listar todas las carpetas de trials\n",
        "    trial_folders = glob.glob(os.path.join(base_directory, 'trial_*'))\n",
        "\n",
        "    # Inicializar listas para almacenar los datos de todas las métricas\n",
        "    precision_data = []\n",
        "    recall_data = []\n",
        "    map50_data = []\n",
        "\n",
        "    # Recorrer cada carpeta de trial\n",
        "    for i, folder in enumerate(trial_folders):\n",
        "        if (i + 1) in selected_trials:  # Filtrar solo los trials seleccionados\n",
        "            results_file = os.path.join(folder, 'results.csv')\n",
        "            if os.path.exists(results_file):\n",
        "                # Leer el archivo CSV\n",
        "                df = pd.read_csv(results_file)\n",
        "\n",
        "                # Limpiar nombres de columnas\n",
        "                df = clean_column_names(df)\n",
        "\n",
        "                # Imprimir los nombres de las columnas para depuración\n",
        "                print(f\"Columnas en '{results_file}': {df.columns.tolist()}\")\n",
        "\n",
        "                # Intentar guardar las columnas de interés\n",
        "                try:\n",
        "                    precision_data.append(df['metrics/precision(M)'].values)\n",
        "                    recall_data.append(df['metrics/recall(M)'].values)\n",
        "                    map50_data.append(df['metrics/mAP50(M)'].values)\n",
        "                except KeyError as e:\n",
        "                    print(f\"Columna no encontrada: {e}\")\n",
        "\n",
        "    # Convertir listas a DataFrames para facilitar el cálculo de la media\n",
        "    precision_df = pd.DataFrame(precision_data).transpose()\n",
        "    recall_df = pd.DataFrame(recall_data).transpose()\n",
        "    map50_df = pd.DataFrame(map50_data).transpose()\n",
        "\n",
        "    # Calcular las medias\n",
        "    precision_mean = precision_df.mean(axis=1)\n",
        "    recall_mean = recall_df.mean(axis=1)\n",
        "    map50_mean = map50_df.mean(axis=1)\n",
        "\n",
        "    # Plotear las métricas\n",
        "    fig, axs = plt.subplots(3, 1, figsize=(10, 15))\n",
        "\n",
        "    # Plot Precision\n",
        "    for trial_data in precision_data:\n",
        "        axs[0].plot(trial_data, color='lightblue', alpha=0.5)\n",
        "    axs[0].plot(precision_mean, color='darkblue', label='Mean Precision', linewidth=2)\n",
        "    axs[0].set_title('Precision Over Epochs')\n",
        "    axs[0].set_xlabel('Epochs')\n",
        "    axs[0].set_ylabel('Precision')\n",
        "    axs[0].legend()\n",
        "\n",
        "    # Plot Recall\n",
        "    for trial_data in recall_data:\n",
        "        axs[1].plot(trial_data, color='lightgreen', alpha=0.5)\n",
        "    axs[1].plot(recall_mean, color='darkgreen', label='Mean Recall', linewidth=2)\n",
        "    axs[1].set_title('Recall Over Epochs')\n",
        "    axs[1].set_xlabel('Epochs')\n",
        "    axs[1].set_ylabel('Recall')\n",
        "    axs[1].legend()\n",
        "\n",
        "    # Plot mAP50\n",
        "    for trial_data in map50_data:\n",
        "        axs[2].plot(trial_data, color='lightcoral', alpha=0.5)\n",
        "    axs[2].plot(map50_mean, color='darkred', label='Mean mAP50', linewidth=2)\n",
        "    axs[2].set_title('mAP50 Over Epochs')\n",
        "    axs[2].set_xlabel('Epochs')\n",
        "    axs[2].set_ylabel('mAP50')\n",
        "    axs[2].legend()\n",
        "\n",
        "    # Ajustar el espaciado\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "# Uso de la función\n",
        "base_directory = '/content/models/YoloV8_250Epoch_V1'\n",
        "selected_trials = [5, 15, 1]\n",
        "plot_metrics_from_trials(base_directory, selected_trials)\n"
      ],
      "metadata": {
        "id": "816t5TFknt2k"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import glob\n",
        "\n",
        "def clean_column_names(df):\n",
        "    # Eliminar espacios en blanco al inicio y al final de los nombres de las columnas\n",
        "    df.columns = df.columns.str.strip()\n",
        "    return df\n",
        "\n",
        "def plot_best_trials_metrics(base_directory, best_trials):\n",
        "    # Inicializar listas para almacenar los datos de las métricas\n",
        "    precision_data = []\n",
        "    recall_data = []\n",
        "    map50_data = []\n",
        "\n",
        "    # Recorrer los mejores trials\n",
        "    for trial_number in best_trials:\n",
        "        trial_folder = os.path.join(base_directory, f'trial_{trial_number}')\n",
        "        results_file = os.path.join(trial_folder, 'results.csv')\n",
        "        if os.path.exists(results_file):\n",
        "            # Leer el archivo CSV\n",
        "            df = pd.read_csv(results_file)\n",
        "\n",
        "            # Limpiar nombres de columnas\n",
        "            df = clean_column_names(df)\n",
        "\n",
        "            # Guardar las columnas de interés\n",
        "            precision_data.append(df['metrics/precision(M)'].values)\n",
        "            recall_data.append(df['metrics/recall(M)'].values)\n",
        "            map50_data.append(df['metrics/mAP50(M)'].values)\n",
        "\n",
        "    # Convertir listas a DataFrames para facilitar el cálculo de la media\n",
        "    precision_df = pd.DataFrame(precision_data).transpose()\n",
        "    recall_df = pd.DataFrame(recall_data).transpose()\n",
        "    map50_df = pd.DataFrame(map50_data).transpose()\n",
        "\n",
        "    # Calcular las medias\n",
        "    precision_mean = precision_df.mean(axis=1)\n",
        "    recall_mean = recall_df.mean(axis=1)\n",
        "    map50_mean = map50_df.mean(axis=1)\n",
        "\n",
        "    # Plotear las métricas\n",
        "    fig, axs = plt.subplots(3, 1, figsize=(10, 15))\n",
        "\n",
        "    # Plot Precision\n",
        "    for trial_data in precision_data:\n",
        "        axs[0].plot(trial_data, color='lightblue', alpha=0.5)\n",
        "    axs[0].plot(precision_mean, color='darkblue', label='Mean Precision', linewidth=2)\n",
        "    axs[0].set_title('Precision Over Epochs (Best Trials)')\n",
        "    axs[0].set_xlabel('Epochs')\n",
        "    axs[0].set_ylabel('Precision')\n",
        "    axs[0].legend()\n",
        "\n",
        "    # Plot Recall\n",
        "    for trial_data in recall_data:\n",
        "        axs[1].plot(trial_data, color='lightgreen', alpha=0.5)\n",
        "    axs[1].plot(recall_mean, color='darkgreen', label='Mean Recall', linewidth=2)\n",
        "    axs[1].set_title('Recall Over Epochs (Best Trials)')\n",
        "    axs[1].set_xlabel('Epochs')\n",
        "    axs[1].set_ylabel('Recall')\n",
        "    axs[1].legend()\n",
        "\n",
        "    # Plot mAP50\n",
        "    for trial_data in map50_data:\n",
        "        axs[2].plot(trial_data, color='lightcoral', alpha=0.5)\n",
        "    axs[2].plot(map50_mean, color='darkred', label='Mean mAP50', linewidth=2)\n",
        "    axs[2].set_title('mAP50 Over Epochs (Best Trials)')\n",
        "    axs[2].set_xlabel('Epochs')\n",
        "    axs[2].set_ylabel('mAP50')\n",
        "    axs[2].legend()\n",
        "\n",
        "    # Ajustar el espaciado\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "# Usar la función con los 3 mejores trials\n",
        "base_directory = '/content/models/YoloV8_250Epoch_V1'\n",
        "# Supongamos que has calculado los mejores 3 trials previamente\n",
        "best_3_trials = [5, 15, 1]  # Reemplaza con los números reales de los mejores trials\n",
        "\n",
        "plot_best_trials_metrics(base_directory, best_3_trials)"
      ],
      "metadata": {
        "id": "rRtVQK_qOxQ5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import glob\n",
        "\n",
        "def clean_column_names(df):\n",
        "    # Eliminar espacios en blanco al inicio y al final de los nombres de las columnas\n",
        "    df.columns = df.columns.str.strip()\n",
        "    return df\n",
        "\n",
        "def plot_last_epoch_values(base_directory):\n",
        "    # Listar todas las carpetas de trials\n",
        "    trial_folders = sorted(glob.glob(os.path.join(base_directory, 'trial_*')), key=lambda x: int(os.path.basename(x).split('_')[1]))\n",
        "\n",
        "    # Inicializar listas para almacenar los datos del último epoch\n",
        "    all_precision_last_epoch = []\n",
        "    all_recall_last_epoch = []\n",
        "    all_map50_last_epoch = []\n",
        "\n",
        "    # Recorrer cada carpeta de trial\n",
        "    for folder in trial_folders:\n",
        "        trial_number = int(os.path.basename(folder).split('_')[1])\n",
        "        results_file = os.path.join(folder, 'results.csv')\n",
        "        if os.path.exists(results_file):\n",
        "            # Leer el archivo CSV\n",
        "            df = pd.read_csv(results_file)\n",
        "\n",
        "            # Limpiar nombres de columnas\n",
        "            df = clean_column_names(df)\n",
        "\n",
        "            # Obtener el último epoch\n",
        "            last_epoch = df.iloc[-1]\n",
        "\n",
        "            # Extraer las métricas del último epoch\n",
        "            precision = last_epoch.get('metrics/precision(M)', None)\n",
        "            recall = last_epoch.get('metrics/recall(M)', None)\n",
        "            map50 = last_epoch.get('metrics/mAP50(M)', None)\n",
        "\n",
        "            # Agregar datos a las listas\n",
        "            all_precision_last_epoch.append(precision)\n",
        "            all_recall_last_epoch.append(recall)\n",
        "            all_map50_last_epoch.append(map50)\n",
        "\n",
        "    # Graficar las métricas del último epoch\n",
        "    fig, axs = plt.subplots(3, 1, figsize=(12, 18))\n",
        "\n",
        "    # Plot Precision\n",
        "    axs[0].plot(range(1, len(all_precision_last_epoch) + 1), all_precision_last_epoch, marker='o', linestyle='-', color='blue')\n",
        "    axs[0].set_title('Precision at Last Epoch')\n",
        "    axs[0].set_xlabel('Trial Number')\n",
        "    axs[0].set_ylabel('Precision')\n",
        "    axs[0].grid(True)\n",
        "\n",
        "    # Plot Recall\n",
        "    axs[1].plot(range(1, len(all_recall_last_epoch) + 1), all_recall_last_epoch, marker='o', linestyle='-', color='green')\n",
        "    axs[1].set_title('Recall at Last Epoch')\n",
        "    axs[1].set_xlabel('Trial Number')\n",
        "    axs[1].set_ylabel('Recall')\n",
        "    axs[1].grid(True)\n",
        "\n",
        "    # Plot mAP50\n",
        "    axs[2].plot(range(1, len(all_map50_last_epoch) + 1), all_map50_last_epoch, marker='o', linestyle='-', color='red')\n",
        "    axs[2].set_title('mAP50 at Last Epoch')\n",
        "    axs[2].set_xlabel('Trial Number')\n",
        "    axs[2].set_ylabel('mAP50')\n",
        "    axs[2].grid(True)\n",
        "\n",
        "    # Ajustar el espaciado\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "# Ejecutar la función para graficar los valores del último epoch\n",
        "base_directory = '/content/models/YoloV8_250Epoch_V1'\n",
        "plot_last_epoch_values(base_directory)\n"
      ],
      "metadata": {
        "id": "jDJ-OhS9RJnl"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}