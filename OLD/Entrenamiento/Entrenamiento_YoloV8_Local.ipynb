{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "view-in-github"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/JorgeAnsotegui/TFM/blob/main/YoloV8/Entrenamiento_YoloV8.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LhUopx5sGliq"
      },
      "source": [
        "**Importamos las librerias y modulos necesarios:**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "eotMLol5O5G0"
      },
      "outputs": [],
      "source": [
        "from ultralytics import YOLO\n",
        "from matplotlib import pyplot as plt\n",
        "from PIL import Image"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d0apxZsj2xBh"
      },
      "source": [
        "**Import a model and populate it with pre-trained weights.**\n",
        "<p>\n",
        "Here, we are importing an instance segmentation model with weights. For a list of pre-trained models, checkout: https://docs.ultralytics.com/models/yolov8/#key-features"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bfhadgmPUWTm",
        "outputId": "6d54c344-cdfe-4dca-e3cc-81a253ca9876"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Downloading https://github.com/ultralytics/assets/releases/download/v8.2.0/yolov8n-seg.pt to 'yolov8n-seg.pt'...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 6.74M/6.74M [00:00<00:00, 15.7MB/s]\n"
          ]
        }
      ],
      "source": [
        "#Instance\n",
        "model = YOLO('yolov8n-seg.yaml')  # build a new model from YAML\n",
        "model = YOLO('yolov8n-seg.pt')  # Transfer the weights from a pretrained model (recommended for training)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6BFiNz2LtFxJ"
      },
      "source": [
        "On colab, you may encounter encoding issues while working with certain libraries (e.g., installing roboflow) so let's go ahead and run the following cell.  "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "0pBNHHqscZ9p"
      },
      "outputs": [],
      "source": [
        "#Withut this Colab is giving an error when installing Roboflow\n",
        "# import locale\n",
        "# import os\n",
        "# locale.getpreferredencoding = lambda: \"UTF-8\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0ucPAX1O38xv"
      },
      "source": [
        "Let us load the YAML file that contains the names of our classes, number of classes and the directories for train, valid, and test datasets, respectively."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vVzvL6d1fhGH",
        "outputId": "be3cd02d-ad4a-4a4b-bb21-d049f6f2957c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "train: ../train/images\n",
            "val: ../val/images\n",
            "test: ../test/images\n",
            "\n",
            "nc: 1\n",
            "names: ['Polipo']\n",
            "\n",
            "roboflow:\n",
            "  workspace: master-c9yad\n",
            "  project: polipos\n",
            "  version: 1\n",
            "  license: CC BY 4.0\n",
            "  url: https://universe.roboflow.com/master-c9yad/polipos/dataset/1"
          ]
        }
      ],
      "source": [
        "yaml = \"Dataset\\Polipos265_Detectron2_YoloV8\\data.yaml\"\n",
        "# this is the YAML file Roboflow wrote for us that we're loading into this notebook with our data\n",
        "%cat Dataset\\Polipos265_Detectron2_YoloV8\\data.yaml"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "6-9DlovCf3e-"
      },
      "outputs": [],
      "source": [
        "# define number of classes based on YAML\n",
        "import yaml\n",
        "with open(yaml, 'r') as stream:\n",
        "    num_classes = str(yaml.safe_load(stream)['nc'])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Mxm0iW8vLCDo"
      },
      "source": [
        "**Train the model**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 49,
      "metadata": {
        "id": "bvHk6gThrzXQ"
      },
      "outputs": [],
      "source": [
        "ruta_raiz = \"models/YoloV8_Models/results/\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 50,
      "metadata": {
        "id": "b7JOR8RrpXtZ"
      },
      "outputs": [],
      "source": [
        "#Define a project --> Destination directory for all results\n",
        "project = ruta_raiz\n",
        "#Define subdirectory for this specific training\n",
        "name = \"250_epochs-\" #note that if you run the training again, it creates a directory: 3_epochs-2\n",
        "ruta_modelo = os.path.join(ruta_raiz, name)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jLA_UWXEXxbz",
        "outputId": "746757ed-b012-48f3-a083-bc91b65c05b6"
      },
      "outputs": [],
      "source": [
        "# Train the model\n",
        "results = model.train(data=yaml,\n",
        "                      project=project,\n",
        "                      name=name,\n",
        "                      epochs=250,\n",
        "                      patience=0, # I am setting patience=0 to disable early stopping.\n",
        "                      batch=4,\n",
        "                      imgsz=512)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PTl5LbJXtFlo"
      },
      "outputs": [],
      "source": [
        "# Start tensorboard\n",
        "# Launch after you have started training\n",
        "# # %reload_ext tensorboard\n",
        "%load_ext tensorboard\n",
        "%tensorboard --logdir ruta_modelo --port 6007"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W3ylq4uvLG8y"
      },
      "source": [
        "All training curves, metrics, and other results are stored as images in the 'runs' directory. Let us open a couple of these images. <p>\n",
        "Please note that from here on I will be working the model that I've already trained for 50 epochs."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "z2PpCJBUh2E6"
      },
      "outputs": [],
      "source": [
        "from IPython.display import Image"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "VVjGUgq6h1iq"
      },
      "outputs": [],
      "source": [
        "ruta_imagen = os.path.join(ruta_modelo, \"results.png\")\n",
        "Image(filename=ruta_imagen)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dmbBmrKAuMCq"
      },
      "outputs": [],
      "source": [
        "ruta_train_batch = os.path.join(ruta_modelo, \"train_batch2.jpg\")\n",
        "Image(filename=ruta_train_batch, width=900)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rNq5pLQJurtl"
      },
      "source": [
        "**Run inference**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OkIJB__zLXm9"
      },
      "source": [
        "Now that our model is trained, we can use it for inference."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SJRIjsEIutM7",
        "outputId": "9a3fe193-d7bc-49d9-a840-fdcccd5cc973"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "/content/drive/MyDrive/TFM/models/YoloV8_Models/results/3_epochs-/weights/last.pt\n",
            "/content/drive/MyDrive/TFM/models/YoloV8_Models/results/3_epochs-/weights/best.pt\n"
          ]
        }
      ],
      "source": [
        "import glob\n",
        "\n",
        "#List the saved models in 'runs' directory. Note that you will see multiple 'train' subdirectories numbered 1, 2, 3, etc. The exact number depends on the number of epochs.\n",
        "ruta_weights = os.path.join(ruta_modelo, \"weights\")\n",
        "\n",
        "# Usar glob para obtener la lista de archivos en la ruta especificada\n",
        "archivos_en_ruta = glob.glob(ruta_weights + \"/*\")\n",
        "\n",
        "# Mostrar los archivos encontrados\n",
        "for archivo in archivos_en_ruta:\n",
        "    print(archivo)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3cue9KgoLn-e"
      },
      "source": [
        "You can load the best model or the latest. I am picking the latest."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "t5PjdDqQvdRQ"
      },
      "outputs": [],
      "source": [
        "ruta_last_weight = os.path.join(ruta_weights, \"last.pt\")\n",
        "\n",
        "my_new_model = YOLO(ruta_last_weight)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1OErkX_wLsXs"
      },
      "source": [
        "Load an image and perform inference (segmentation)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "N3-0Ny5mx3a9"
      },
      "outputs": [],
      "source": [
        "import random\n",
        "# Directorio que contiene las imágenes de prueba\n",
        "ruta_imagenes = \"/content/drive/MyDrive/TFM/dataset_Detectron2_V3/test/images\"\n",
        "\n",
        "# Obtener la lista de nombres de archivo en el directorio\n",
        "archivos = os.listdir(ruta_imagenes)\n",
        "\n",
        "# Elegir un nombre de archivo al azar\n",
        "nombre_archivo = random.choice(archivos)\n",
        "\n",
        "# Ruta completa de la imagen seleccionada\n",
        "ruta_imagen = os.path.join(ruta_imagenes, nombre_archivo)\n",
        "\n",
        "# Hacer la inferencia en la imagen seleccionada\n",
        "new_results = my_new_model.predict(ruta_imagen, conf=0.5)  # Ajusta el umbral de confianza según sea necesario"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tS9ItP1Vv6-e"
      },
      "outputs": [],
      "source": [
        "new_image = '/content/drive/MyDrive/ColabNotebooks/data/NuInsSeg_Nuclei_dataset/yolo_dataset/test/images/human_liver_22.png'\n",
        "new_results = my_new_model.predict(new_image, conf=0.5)  #Adjust conf threshold\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vm21DQKmLwy8"
      },
      "source": [
        "The results are stored in a variable 'new_results'. Since we only have one image for segmentation, we will only have one set of results. Therefore, let us work with that one result."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "q5IbL7to_Qhe"
      },
      "outputs": [],
      "source": [
        "# Suponiendo que new_results[0] es una instancia de algún objeto que tiene un método plot() que devuelve la imagen\n",
        "new_result_array = new_results[0].plot()\n",
        "\n",
        "# Si new_result_array es el resultado de la función plot(), y es una imagen en formato RGB o BGR\n",
        "\n",
        "# Si la imagen está en formato BGR, es posible que necesite convertirla a RGB antes de mostrarla con matplotlib\n",
        "new_result_array_rgb = new_result_array[:, :, ::-1]  # Esta línea invierte el orden de los canales de color (BGR a RGB)\n",
        "\n",
        "# Crear una figura de matplotlib y mostrar la imagen\n",
        "plt.figure(figsize=(9, 9))\n",
        "plt.imshow(new_result_array_rgb)\n",
        "plt.axis('off')  # Desactivar los ejes si no son necesarios\n",
        "\n",
        "# Mostrar la figura\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f74DJ0hHC6mq"
      },
      "source": [
        "# Segmenting and analyzing multiple images"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HGHCbM_sCubp"
      },
      "source": [
        "Now, let us segment all our test images, perform measurements for all objects, capture them into a pandas dataframe and save the dataframe into a csv file."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tjq3rSFAhScy",
        "outputId": "5b3bee6b-1375-4e4f-fd9a-7b1e83b6a897"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n",
            "0: 512x512 58 Nucleis, 15.4ms\n",
            "Speed: 3.7ms preprocess, 15.4ms inference, 4.0ms postprocess per image at shape (1, 3, 512, 512)\n",
            "\n",
            "0: 512x512 38 Nucleis, 10.4ms\n",
            "Speed: 2.0ms preprocess, 10.4ms inference, 3.0ms postprocess per image at shape (1, 3, 512, 512)\n",
            "\n",
            "0: 512x512 112 Nucleis, 10.3ms\n",
            "Speed: 2.3ms preprocess, 10.3ms inference, 4.8ms postprocess per image at shape (1, 3, 512, 512)\n",
            "\n",
            "0: 512x512 47 Nucleis, 10.1ms\n",
            "Speed: 2.0ms preprocess, 10.1ms inference, 3.4ms postprocess per image at shape (1, 3, 512, 512)\n",
            "\n",
            "0: 512x512 7 Nucleis, 8.1ms\n",
            "Speed: 3.2ms preprocess, 8.1ms inference, 2.5ms postprocess per image at shape (1, 3, 512, 512)\n",
            "\n",
            "0: 512x512 15 Nucleis, 9.4ms\n",
            "Speed: 2.1ms preprocess, 9.4ms inference, 2.8ms postprocess per image at shape (1, 3, 512, 512)\n",
            "\n",
            "0: 512x512 51 Nucleis, 11.7ms\n",
            "Speed: 1.5ms preprocess, 11.7ms inference, 3.3ms postprocess per image at shape (1, 3, 512, 512)\n",
            "\n",
            "0: 512x512 39 Nucleis, 8.9ms\n",
            "Speed: 2.2ms preprocess, 8.9ms inference, 4.4ms postprocess per image at shape (1, 3, 512, 512)\n",
            "\n",
            "0: 512x512 183 Nucleis, 8.3ms\n",
            "Speed: 1.6ms preprocess, 8.3ms inference, 5.9ms postprocess per image at shape (1, 3, 512, 512)\n",
            "\n",
            "0: 512x512 64 Nucleis, 10.4ms\n",
            "Speed: 1.8ms preprocess, 10.4ms inference, 3.5ms postprocess per image at shape (1, 3, 512, 512)\n",
            "\n",
            "0: 512x512 31 Nucleis, 8.8ms\n",
            "Speed: 3.6ms preprocess, 8.8ms inference, 3.0ms postprocess per image at shape (1, 3, 512, 512)\n",
            "\n",
            "0: 512x512 111 Nucleis, 11.0ms\n",
            "Speed: 1.5ms preprocess, 11.0ms inference, 4.2ms postprocess per image at shape (1, 3, 512, 512)\n",
            "\n",
            "0: 512x512 34 Nucleis, 10.9ms\n",
            "Speed: 1.5ms preprocess, 10.9ms inference, 2.9ms postprocess per image at shape (1, 3, 512, 512)\n",
            "\n",
            "0: 512x512 28 Nucleis, 10.2ms\n",
            "Speed: 2.7ms preprocess, 10.2ms inference, 5.4ms postprocess per image at shape (1, 3, 512, 512)\n",
            "\n",
            "0: 512x512 11 Nucleis, 9.0ms\n",
            "Speed: 1.3ms preprocess, 9.0ms inference, 2.7ms postprocess per image at shape (1, 3, 512, 512)\n",
            "\n",
            "0: 512x512 131 Nucleis, 11.1ms\n",
            "Speed: 1.6ms preprocess, 11.1ms inference, 4.8ms postprocess per image at shape (1, 3, 512, 512)\n",
            "\n",
            "0: 512x512 112 Nucleis, 10.0ms\n",
            "Speed: 2.6ms preprocess, 10.0ms inference, 4.3ms postprocess per image at shape (1, 3, 512, 512)\n",
            "\n",
            "0: 512x512 51 Nucleis, 11.9ms\n",
            "Speed: 1.5ms preprocess, 11.9ms inference, 3.8ms postprocess per image at shape (1, 3, 512, 512)\n",
            "\n",
            "0: 512x512 36 Nucleis, 10.1ms\n",
            "Speed: 2.0ms preprocess, 10.1ms inference, 3.4ms postprocess per image at shape (1, 3, 512, 512)\n",
            "\n",
            "0: 512x512 64 Nucleis, 10.7ms\n",
            "Speed: 1.6ms preprocess, 10.7ms inference, 3.4ms postprocess per image at shape (1, 3, 512, 512)\n",
            "\n",
            "0: 512x512 43 Nucleis, 9.9ms\n",
            "Speed: 1.2ms preprocess, 9.9ms inference, 3.1ms postprocess per image at shape (1, 3, 512, 512)\n",
            "\n",
            "0: 512x512 43 Nucleis, 10.1ms\n",
            "Speed: 1.9ms preprocess, 10.1ms inference, 3.1ms postprocess per image at shape (1, 3, 512, 512)\n",
            "\n",
            "0: 512x512 98 Nucleis, 11.5ms\n",
            "Speed: 1.4ms preprocess, 11.5ms inference, 4.0ms postprocess per image at shape (1, 3, 512, 512)\n",
            "\n",
            "0: 512x512 126 Nucleis, 10.7ms\n",
            "Speed: 1.5ms preprocess, 10.7ms inference, 4.4ms postprocess per image at shape (1, 3, 512, 512)\n",
            "\n",
            "0: 512x512 53 Nucleis, 10.6ms\n",
            "Speed: 1.5ms preprocess, 10.6ms inference, 3.3ms postprocess per image at shape (1, 3, 512, 512)\n",
            "\n",
            "0: 512x512 63 Nucleis, 12.2ms\n",
            "Speed: 2.1ms preprocess, 12.2ms inference, 3.4ms postprocess per image at shape (1, 3, 512, 512)\n",
            "\n",
            "0: 512x512 8 Nucleis, 12.0ms\n",
            "Speed: 1.9ms preprocess, 12.0ms inference, 3.6ms postprocess per image at shape (1, 3, 512, 512)\n",
            "\n",
            "0: 512x512 158 Nucleis, 11.1ms\n",
            "Speed: 1.5ms preprocess, 11.1ms inference, 5.9ms postprocess per image at shape (1, 3, 512, 512)\n",
            "\n",
            "0: 512x512 96 Nucleis, 10.0ms\n",
            "Speed: 1.4ms preprocess, 10.0ms inference, 7.1ms postprocess per image at shape (1, 3, 512, 512)\n",
            "\n",
            "0: 512x512 57 Nucleis, 12.5ms\n",
            "Speed: 1.5ms preprocess, 12.5ms inference, 4.1ms postprocess per image at shape (1, 3, 512, 512)\n",
            "\n",
            "0: 512x512 35 Nucleis, 11.0ms\n",
            "Speed: 1.5ms preprocess, 11.0ms inference, 3.7ms postprocess per image at shape (1, 3, 512, 512)\n",
            "\n",
            "0: 512x512 11 Nucleis, 9.9ms\n",
            "Speed: 1.5ms preprocess, 9.9ms inference, 3.3ms postprocess per image at shape (1, 3, 512, 512)\n",
            "\n",
            "0: 512x512 66 Nucleis, 11.1ms\n",
            "Speed: 1.4ms preprocess, 11.1ms inference, 4.3ms postprocess per image at shape (1, 3, 512, 512)\n",
            "\n",
            "0: 512x512 75 Nucleis, 11.5ms\n",
            "Speed: 1.5ms preprocess, 11.5ms inference, 5.3ms postprocess per image at shape (1, 3, 512, 512)\n",
            "\n",
            "0: 512x512 71 Nucleis, 11.9ms\n",
            "Speed: 1.5ms preprocess, 11.9ms inference, 4.3ms postprocess per image at shape (1, 3, 512, 512)\n",
            "\n",
            "0: 512x512 71 Nucleis, 10.4ms\n",
            "Speed: 1.5ms preprocess, 10.4ms inference, 3.6ms postprocess per image at shape (1, 3, 512, 512)\n",
            "\n",
            "0: 512x512 22 Nucleis, 13.2ms\n",
            "Speed: 1.5ms preprocess, 13.2ms inference, 2.9ms postprocess per image at shape (1, 3, 512, 512)\n",
            "\n",
            "0: 512x512 18 Nucleis, 8.1ms\n",
            "Speed: 1.9ms preprocess, 8.1ms inference, 2.7ms postprocess per image at shape (1, 3, 512, 512)\n",
            "\n",
            "0: 512x512 296 Nucleis, 9.7ms\n",
            "Speed: 2.4ms preprocess, 9.7ms inference, 7.8ms postprocess per image at shape (1, 3, 512, 512)\n",
            "\n",
            "0: 512x512 77 Nucleis, 12.5ms\n",
            "Speed: 1.5ms preprocess, 12.5ms inference, 4.7ms postprocess per image at shape (1, 3, 512, 512)\n",
            "\n",
            "0: 512x512 6 Nucleis, 37.3ms\n",
            "Speed: 1.6ms preprocess, 37.3ms inference, 22.0ms postprocess per image at shape (1, 3, 512, 512)\n",
            "\n",
            "0: 512x512 73 Nucleis, 12.6ms\n",
            "Speed: 1.5ms preprocess, 12.6ms inference, 4.5ms postprocess per image at shape (1, 3, 512, 512)\n",
            "\n",
            "0: 512x512 23 Nucleis, 31.8ms\n",
            "Speed: 1.5ms preprocess, 31.8ms inference, 5.9ms postprocess per image at shape (1, 3, 512, 512)\n",
            "\n",
            "0: 512x512 17 Nucleis, 34.8ms\n",
            "Speed: 3.7ms preprocess, 34.8ms inference, 3.7ms postprocess per image at shape (1, 3, 512, 512)\n",
            "\n",
            "0: 512x512 32 Nucleis, 24.8ms\n",
            "Speed: 1.5ms preprocess, 24.8ms inference, 4.0ms postprocess per image at shape (1, 3, 512, 512)\n",
            "\n",
            "0: 512x512 89 Nucleis, 24.7ms\n",
            "Speed: 1.5ms preprocess, 24.7ms inference, 11.2ms postprocess per image at shape (1, 3, 512, 512)\n",
            "\n",
            "0: 512x512 44 Nucleis, 31.2ms\n",
            "Speed: 2.3ms preprocess, 31.2ms inference, 18.9ms postprocess per image at shape (1, 3, 512, 512)\n",
            "\n",
            "0: 512x512 247 Nucleis, 32.3ms\n",
            "Speed: 1.6ms preprocess, 32.3ms inference, 32.8ms postprocess per image at shape (1, 3, 512, 512)\n",
            "\n",
            "0: 512x512 51 Nucleis, 12.1ms\n",
            "Speed: 1.5ms preprocess, 12.1ms inference, 14.5ms postprocess per image at shape (1, 3, 512, 512)\n",
            "\n",
            "0: 512x512 67 Nucleis, 13.1ms\n",
            "Speed: 1.5ms preprocess, 13.1ms inference, 4.6ms postprocess per image at shape (1, 3, 512, 512)\n",
            "\n",
            "0: 512x512 87 Nucleis, 26.0ms\n",
            "Speed: 3.6ms preprocess, 26.0ms inference, 5.0ms postprocess per image at shape (1, 3, 512, 512)\n",
            "\n",
            "0: 512x512 97 Nucleis, 12.6ms\n",
            "Speed: 1.5ms preprocess, 12.6ms inference, 5.0ms postprocess per image at shape (1, 3, 512, 512)\n",
            "\n",
            "0: 512x512 5 Nucleis, 35.3ms\n",
            "Speed: 3.2ms preprocess, 35.3ms inference, 10.3ms postprocess per image at shape (1, 3, 512, 512)\n",
            "\n",
            "0: 512x512 47 Nucleis, 9.0ms\n",
            "Speed: 3.5ms preprocess, 9.0ms inference, 3.1ms postprocess per image at shape (1, 3, 512, 512)\n",
            "\n",
            "0: 512x512 61 Nucleis, 10.5ms\n",
            "Speed: 1.6ms preprocess, 10.5ms inference, 3.5ms postprocess per image at shape (1, 3, 512, 512)\n",
            "\n",
            "0: 512x512 18 Nucleis, 12.9ms\n",
            "Speed: 3.0ms preprocess, 12.9ms inference, 4.0ms postprocess per image at shape (1, 3, 512, 512)\n",
            "\n",
            "0: 512x512 52 Nucleis, 12.0ms\n",
            "Speed: 3.2ms preprocess, 12.0ms inference, 5.1ms postprocess per image at shape (1, 3, 512, 512)\n",
            "\n",
            "0: 512x512 13 Nucleis, 9.5ms\n",
            "Speed: 3.1ms preprocess, 9.5ms inference, 2.8ms postprocess per image at shape (1, 3, 512, 512)\n",
            "\n",
            "0: 512x512 57 Nucleis, 8.4ms\n",
            "Speed: 3.6ms preprocess, 8.4ms inference, 3.3ms postprocess per image at shape (1, 3, 512, 512)\n",
            "\n",
            "0: 512x512 16 Nucleis, 12.2ms\n",
            "Speed: 1.5ms preprocess, 12.2ms inference, 2.8ms postprocess per image at shape (1, 3, 512, 512)\n",
            "\n",
            "0: 512x512 76 Nucleis, 13.3ms\n",
            "Speed: 1.5ms preprocess, 13.3ms inference, 4.5ms postprocess per image at shape (1, 3, 512, 512)\n",
            "\n",
            "0: 512x512 8 Nucleis, 10.9ms\n",
            "Speed: 1.4ms preprocess, 10.9ms inference, 3.2ms postprocess per image at shape (1, 3, 512, 512)\n",
            "\n",
            "0: 512x512 51 Nucleis, 13.8ms\n",
            "Speed: 4.1ms preprocess, 13.8ms inference, 4.0ms postprocess per image at shape (1, 3, 512, 512)\n",
            "\n",
            "0: 512x512 81 Nucleis, 14.0ms\n",
            "Speed: 1.7ms preprocess, 14.0ms inference, 4.5ms postprocess per image at shape (1, 3, 512, 512)\n",
            "\n",
            "0: 512x512 25 Nucleis, 13.8ms\n",
            "Speed: 3.7ms preprocess, 13.8ms inference, 3.9ms postprocess per image at shape (1, 3, 512, 512)\n",
            "\n",
            "0: 512x512 39 Nucleis, 10.9ms\n",
            "Speed: 1.7ms preprocess, 10.9ms inference, 3.1ms postprocess per image at shape (1, 3, 512, 512)\n",
            "\n",
            "0: 512x512 155 Nucleis, 11.0ms\n",
            "Speed: 1.5ms preprocess, 11.0ms inference, 5.0ms postprocess per image at shape (1, 3, 512, 512)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Object-level information saved to CSV file.\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import csv\n",
        "import cv2\n",
        "import matplotlib.pyplot as plt\n",
        "from skimage.measure import label, regionprops\n",
        "\n",
        "# Directory path to the input images folder\n",
        "input_images_directory = \"/content/drive/MyDrive/ColabNotebooks/data/NuInsSeg_Nuclei_dataset/yolo_dataset/test/images\"\n",
        "\n",
        "# Output directory where the CSV file will be saved\n",
        "output_csv_path = \"/content/drive/MyDrive/ColabNotebooks/data/NuInsSeg_Nuclei_dataset/yolo_dataset/test_results/output_objects_yolo.csv\"\n",
        "\n",
        "# Extract the directory name from the full path\n",
        "output_dir_name = os.path.dirname(output_csv_path)\n",
        "\n",
        "# Check if the directory exists\n",
        "if not os.path.exists(output_dir_name):\n",
        "    os.makedirs(output_dir_name)\n",
        "\n",
        "# List of valid image extensions. This ensures that the code doesn't throw\n",
        "# errors if your directory has non-images, like .json or other text files.\n",
        "valid_extensions = ['.jpg', '.jpeg', '.png', '.bmp', '.tiff', '.gif']\n",
        "\n",
        "# Open the CSV file for writing\n",
        "with open(output_csv_path, 'w', newline='') as csvfile:\n",
        "    csvwriter = csv.writer(csvfile)\n",
        "\n",
        "    # Write the header row in the CSV file\n",
        "    csvwriter.writerow([\"File Name\", \"Class Name\", \"Object Number\", \"Area\", \"Centroid\", \"BoundingBox\"])\n",
        "\n",
        "    # Loop over the images in the input folder\n",
        "    for image_filename in os.listdir(input_images_directory):\n",
        "        # Check if the file has a valid image extension\n",
        "        if not any(image_filename.lower().endswith(ext) for ext in valid_extensions):\n",
        "            continue\n",
        "\n",
        "        image_path = os.path.join(input_images_directory, image_filename)\n",
        "        new_im = cv2.imread(image_path)\n",
        "\n",
        "        # Perform prediction on the new image\n",
        "        new_results = my_new_model.predict(new_im, conf=0.2)  # Adjust conf threshold\n",
        "\n",
        "\n",
        "        # Access the bounding boxes and class labels from new_results\n",
        "        bounding_boxes = new_results[0].boxes.data.cpu().numpy()  # Move to CPU and convert to NumPy array\n",
        "        class_labels = [0 for _ in range(len(bounding_boxes))]  # Assuming all objects are 'Nuclei'\n",
        "\n",
        "        # Write the object-level information to the CSV file\n",
        "        for i, bbox in enumerate(bounding_boxes):\n",
        "            object_number = i + 1\n",
        "            x1, y1, x2, y2 = bbox[:4]  # Only take the first 4 values\n",
        "            area = (x2 - x1) * (y2 - y1)\n",
        "            centroid = ((x1 + x2) / 2, (y1 + y2) / 2)\n",
        "            bounding_box = (x1, y1, x2, y2)\n",
        "\n",
        "            #\n",
        "            class_name = 'Nuclei'  # Since all objects are 'Nuclei' in this example\n",
        "\n",
        "            csvwriter.writerow([image_filename, class_name, object_number, area, centroid, bounding_box])\n",
        "\n",
        "print(\"Object-level information saved to CSV file.\")\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "include_colab_link": true,
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.14"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
